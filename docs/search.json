[
  {
    "objectID": "cs1_practical_two-sample-t-test.html#libraries-and-functions",
    "href": "cs1_practical_two-sample-t-test.html#libraries-and-functions",
    "title": "Student’s t-test",
    "section": "Libraries and functions",
    "text": "Libraries and functions\n\ntidyverseRPython\n\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nlibrary(tidyverse)\nA collection of R packages designed for data science\n\n\nlibrary(rstatix)\nConverts base R stats functions to a tidyverse-friendly format. Also contains extra functionality that we’ll use.\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nrstatix::get_summary_stats()\nComputes summary statistics\n\n\nrstatix::levene_test()\nPerform Levene’s test for equality of variance (non-normally distributed data)\n\n\nbartlett.test()\nPerform Bartlett’s test for equality of variance (normally distributed data)\n\n\nggplot2::stat_qq()\nPlots a Q-Q plot for comparison with a normal distribution.\n\n\nggplot2::stat_qq_line()\nAdds a comparison line to the Q-Q plot.\n\n\n\n\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nlibrary(car)\nCompanion to Applied Regression, provides additional statistical functionality.\n\n\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\naggregate()\nSplits the data into subsets, computes summary statistics for each, and returns the result in a convenient form\n\n\nunstack()\nConverts a stacked data frame into an unstacked data frame (or a list if the lengths of the samples are different)\n\n\nbartlett.test()\nPerform Bartlett’s test for equality of variance (normally distributed data)\n\n\ncar::leveneTest()\nPerform Levene’s test for equality of variance (non-normally distributed data)\n\n\nt.test()\nPerforms a one-sample t-test, Student’s t-test and Welch’s t-test in later sections.\n\n\nqqnorm()\nPlots a Q-Q plot for comparison with a normal distribution.\n\n\nqqline()\nAdds a comparison line to the Q-Q plot.\n\n\nshapiro.test()\nPerforms a Shapiro-Wilk test for normality.\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nplotnine\nThe Python equivalent of ggplot2.\n\n\npandas\nA Python data analysis and manipulation tool.\n\n\nscipy.stats\nA Python module containing statistical functions.\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\npandas.DataFrame.read_csv\nReads in a .csv file\n\n\npandas.DataFrame.head()\nPlots the first few rows\n\n\npandas.DataFrame.describe()\nGives summary statistics\n\n\npandas.DataFrame.groupby()\nGroup DataFrame using a mapper or by a Series of columns\n\n\npandas.DataFrame.query()\nQuery the columns of a DataFrame with a boolean expression\n\n\nscipy.stats.shapiro()\nPerforms the Shapiro-Wilk test\n\n\nscipy.stats.levene()\nPerforms Levene’s test for equality of variance\n\n\nscipy.stats.bartlett()\nPerforms Bartlett’s test for equality of variance\n\n\nscipy.stats.ttest_ind()\nCalculate the T-test for the means of two independent samples of scores\n\n\nscipy.stats.ttest_1samp()\nCalculate the T-test for the mean of ONE group of scores.\n\n\nplotnine.stats.stat_qq()\nPlots a Q-Q plot for comparison with a normal distribution.\n\n\nplotnine.stats.stat_qq_line()\nAdds a comparison line to the Q-Q plot."
  },
  {
    "objectID": "cs1_practical_two-sample-t-test.html#data-and-hypotheses",
    "href": "cs1_practical_two-sample-t-test.html#data-and-hypotheses",
    "title": "Student’s t-test",
    "section": "Data and hypotheses",
    "text": "Data and hypotheses\nFor example, suppose we now measure the body lengths of male guppies (in mm) collected from two rivers in Trinidad; the Aripo and the Guanapo. We want to test whether the mean body length differs between samples. We form the following null and alternative hypotheses:\n\n\\(H_0\\): The mean body length does not differ between the two groups \\((\\mu A = \\mu G)\\)\n\\(H_1\\): The mean body length does differ between the two groups \\((\\mu A \\neq \\mu G)\\)\n\nWe use a two-sample, two-tailed t-test to see if we can reject the null hypothesis.\n\nWe use a two-sample test because we now have two samples.\nWe use a two-tailed t-test because we want to know if our data suggest that the true (population) means are different from one another rather than that one mean is specifically bigger or smaller than the other.\nWe’re using Student’s t-test because the sample sizes are big and because we’re assuming that the parent populations have equal variance (We can check this later).\n\nThe data are stored in the file data/CS1-twosample.csv.\nLet’s read in the data and have a quick look at the first rows to see how the data is structured.\nMake sure you have downloaded the data (see: Datasets) and placed it within your working directory.\n\ntidyverseRPython\n\n\nFirst we load the relevant libraries:\n\n# load tidyverse\nlibrary(tidyverse)\n\n# load rstatix, a tidyverse-friendly stats package\nlibrary(rstatix)\n\nWe then read in the data and create a table containing the data.\n\nrivers <- read_csv(\"data/CS1-twosample.csv\")\n\nrivers\n\n# A tibble: 68 × 2\n   river   length\n   <chr>    <dbl>\n 1 Guanapo   19.1\n 2 Guanapo   23.3\n 3 Guanapo   18.2\n 4 Guanapo   16.4\n 5 Guanapo   19.7\n 6 Guanapo   16.6\n 7 Guanapo   17.5\n 8 Guanapo   19.9\n 9 Guanapo   19.1\n10 Guanapo   18.8\n# … with 58 more rows\n\n\n\n\n\nrivers_r <- read.csv(\"data/CS1-twosample.csv\")\n\nhead(rivers_r)\n\n    river length\n1 Guanapo   19.1\n2 Guanapo   23.3\n3 Guanapo   18.2\n4 Guanapo   16.4\n5 Guanapo   19.7\n6 Guanapo   16.6\n\n\n\n\n\nrivers_py = pd.read_csv(\"data/CS1-twosample.csv\")\n\nrivers_py.head()\n\n     river  length\n0  Guanapo    19.1\n1  Guanapo    23.3\n2  Guanapo    18.2\n3  Guanapo    16.4\n4  Guanapo    19.7"
  },
  {
    "objectID": "cs1_practical_two-sample-t-test.html#cs1-students-sumvisual",
    "href": "cs1_practical_two-sample-t-test.html#cs1-students-sumvisual",
    "title": "Student’s t-test",
    "section": "Summarise and visualise",
    "text": "Summarise and visualise\nLet’s first summarise the data.\n\ntidyverseRPython\n\n\n\nsummary(rivers)\n\n    river               length     \n Length:68          Min.   :11.20  \n Class :character   1st Qu.:18.40  \n Mode  :character   Median :19.30  \n                    Mean   :19.46  \n                    3rd Qu.:20.93  \n                    Max.   :26.40  \n\n\nThis gives us the standard summary statistics, but in this case we have more than one group (Aripo and Guanapo), so it might be helpful to get summary statistics per group. One way of doing this is by using the get_summary_stats() function from the rstatix library.\n\n# get common summary stats for the length column\nrivers %>% \n  group_by(river) %>% \n  get_summary_stats(type = \"common\")\n\n# A tibble: 2 × 11\n  river   variable     n   min   max median   iqr  mean    sd    se    ci\n  <chr>   <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Aripo   length      39  17.5  26.4   20.1   2.2  20.3  1.78 0.285 0.577\n2 Guanapo length      29  11.2  23.3   18.8   2.2  18.3  2.58 0.48  0.983\n\n\nNumbers might not always give you the best insight into your data, so we also visualise our data:\n\nrivers %>% \n  ggplot(aes(x = river, y = length)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nsummary(rivers_r)\n\n    river               length     \n Length:68          Min.   :11.20  \n Class :character   1st Qu.:18.40  \n Mode  :character   Median :19.30  \n                    Mean   :19.46  \n                    3rd Qu.:20.93  \n                    Max.   :26.40  \n\n\nThis gives us the standard summary statistics, but in this case we have more than one group (Aripo and Guanapo), so it might be helpful to get summary statistics per group. We can do this in base R using the aggregate() function.\n\naggregate(length ~ river,\n          data = rivers_r,\n          summary)\n\n    river length.Min. length.1st Qu. length.Median length.Mean length.3rd Qu.\n1   Aripo    17.50000       19.10000      20.10000    20.33077       21.30000\n2 Guanapo    11.20000       17.50000      18.80000    18.29655       19.70000\n  length.Max.\n1    26.40000\n2    23.30000\n\n\n\nThe first argument defines the variable that is being used (length) and grouping (river)\nThe second argument is the data frame that is used\nThe third argument defines the function that is applied across the subsets (in this case that’s the summary() function)\n\nNumbers might not always give you the best insight into your data, so we also visualise our data:\n\nboxplot(length ~ river,\n        data = rivers_r)\n\n\n\n\nWe can use a very similar notation as we did for the summary statistics (length ~ river), so a box plot is created per group.\n\n\n\nrivers_py.describe()\n\n          length\ncount  68.000000\nmean   19.463235\nstd     2.370081\nmin    11.200000\n25%    18.400000\n50%    19.300000\n75%    20.925000\nmax    26.400000\n\n\nThis gives us the standard summary statistics, but in this case we have more than one group (Aripo and Guanapo), so it might be helpful to get summary statistics per group. Here we use the pd.groupby() function to group by river. We only want to have summary statistics for the length variable, so we specify that as well:\n\nrivers_py.groupby(\"river\")[\"length\"].describe()\n\n         count       mean       std   min   25%   50%   75%   max\nriver                                                            \nAripo     39.0  20.330769  1.780620  17.5  19.1  20.1  21.3  26.4\nGuanapo   29.0  18.296552  2.584636  11.2  17.5  18.8  19.7  23.3\n\n\nNumbers might not always give you the best insight into your data, so we also visualise our data:\n\n(\n  ggplot(rivers_py, aes(x = \"river\", y = \"length\"))\n  + geom_boxplot()\n)\n\n\n\n\n\n\n\nThe box plot does appear to suggest that the two samples have different means, and moreover that the guppies in Guanapo may be smaller than the guppies in Aripo. It isn’t immediately obvious that the two populations don’t have equal variances though (box plots are not quite the right tool for this), so we plough on. Who ever said statistics would be glamorous?"
  },
  {
    "objectID": "cs1_practical_two-sample-t-test.html#assumptions",
    "href": "cs1_practical_two-sample-t-test.html#assumptions",
    "title": "Student’s t-test",
    "section": "Assumptions",
    "text": "Assumptions\nIn order to use a Student’s t-test (and for the results to be strictly valid) we have to make three assumptions:\n\nThe parent distributions from which the samples are taken are both normally distributed (which would lead to the sample data being normally distributed too).\nEach data point in the samples is independent of the others.\nThe parent distributions should have the same variance.\n\nIn this example the first assumption can be ignored as the sample sizes are large enough (because of maths, with Aripo containing 39 and Guanapo 29 samples). If the samples were smaller then we would use the tests from the previous section.\nThe second point we can do nothing about unless we know how the data were collected, so again we ignore it.\nThe third point regarding equality of variance can be tested using either Bartlett’s test (if the samples are normally distributed) or Levene’s test (if the samples are not normally distributed).\nThis is where it gets a bit trickier. Although we don’t care if the samples are normally distributed for the t-test to be valid (because the sample size is big enough to compensate), we do need to know if they are normally distributed in order to decide which variance test to use.\nSo we perform a Shapiro-Wilk test on both samples separately.\n\ntidyverseRPython\n\n\nWe can use the group_by() function to group the data by river, then we perform the Shapiro-Wilk test on the length measurements:\n\n# group data by river and perform test\nrivers %>% \n  group_by(river) %>% \n  shapiro_test(length)\n\n# A tibble: 2 × 4\n  river   variable statistic      p\n  <chr>   <chr>        <dbl>  <dbl>\n1 Aripo   length       0.936 0.0280\n2 Guanapo length       0.949 0.176 \n\n\n\n\nBefore we can do that, we need to convert the data to a format where the data is split by river:\n\n# create a new object (a list) that contains the unstacked data\nuns_rivers <- unstack(rivers_r, form = length ~ river)\n# have a look at the data\nuns_rivers\n\nNow that we’ve separated the data by river we can perform the Shapiro-Wilk test:\n\nshapiro.test(uns_rivers$Aripo)\n\n\n    Shapiro-Wilk normality test\n\ndata:  uns_rivers$Aripo\nW = 0.93596, p-value = 0.02802\n\nshapiro.test(uns_rivers$Guanapo)\n\n\n    Shapiro-Wilk normality test\n\ndata:  uns_rivers$Guanapo\nW = 0.94938, p-value = 0.1764\n\n\n\n\nWe first need to split the data by river.\n\nrivers_py.groupby(\"river\")[\"length\"] \\\n.apply(lambda x: pd.Series(stats.shapiro(x), index=['W-stat','p-value'])) \\\n.reset_index()\n\n     river  level_1    length\n0    Aripo   W-stat  0.935958\n1    Aripo  p-value  0.028023\n2  Guanapo   W-stat  0.949384\n3  Guanapo  p-value  0.176420\n\n\nThe code is a bit convoluted and perhaps there is a more efficient way that I’m not aware of. Anyway, we can do this with the groupby() function from pandas. Next, we only select the length measurements and use the .apply() function to apply the stats.shapiro() test over each group. This returns two values per group: the W-statistic that the Shapiro-Wilk test uses and, the value we’re most interested in, the p-value. Lastly,we use the .reset_index() function to repeat the grouping name.\n\n\n\nWe can see that whilst the Guanapo data is probably normally distributed (p = 0.1764 > 0.05), the Aripo data is unlikely to be normally distributed (p = 0.02802 < 0.05). Remember that the p-value gives the probability of observing each sample if the parent population is actually normally distributed.\nThe Shapiro-Wilk test is quite sensitive to sample size. This means that if you have a large sample then even small deviations from normality will cause the sample to fail the test, whereas smaller samples are allowed to pass with much larger deviations. Here the Aripo data has nearly 40 points in it compared with the Guanapo data and so it is much easier for the Aripo sample to fail compared with the Guanapo data."
  },
  {
    "objectID": "cs1_practical_two-sample-t-test.html#exercise-qq-rivers",
    "href": "cs1_practical_two-sample-t-test.html#exercise-qq-rivers",
    "title": "Student’s t-test",
    "section": "Exercise: Q-Q plots rivers",
    "text": "Exercise: Q-Q plots rivers\nCreate the Q-Q plots for the two samples and discuss with your neighbour what you see in light of the results from the above Shapiro-Wilk test.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\ntidyverseRPython\n\n\n\n# we group the data by river\n# then create a panel per river\n# containing the Q-Q plot for that river\nrivers %>% \n  ggplot(aes(sample = length)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  facet_wrap(facets = vars(river))\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nqqnorm(uns_rivers$Aripo, main = \"Aripo\")\nqqline(uns_rivers$Aripo, col = \"red\")\n\nqqnorm(uns_rivers$Guanapo, main = \"Guanapo\")\nqqline(uns_rivers$Guanapo, col = \"red\")\n\n\n\n\n\n\n\n(\n  ggplot(rivers_py, aes(sample = \"length\"))\n  + stat_qq()\n  + stat_qq_line(colour = \"red\")\n  + facet_wrap(\"river\")\n)\n\n\n\n\n\n\n\nThe Q-Q plots show the opposite of what we found with the Shapiro-Wilk tests: the data for Aripo look pretty normally distributed, whereas the assumption of normality for the Guanapo data is less certain.\nWhat to do? Well, you could be conservative and state that you are not confident that the data in either group are normally distributed. That would be a perfectly reasonable conclusion.\nI would personally not have issues with stating that the Aripo data are probably normally distributed enough."
  },
  {
    "objectID": "cs1_practical_two-sample-t-test.html#equality-of-variance",
    "href": "cs1_practical_two-sample-t-test.html#equality-of-variance",
    "title": "Student’s t-test",
    "section": "Equality of variance",
    "text": "Equality of variance\n\n\n\n\n\n\nTip\n\n\n\nRemember that statistical tests do not provide answers, they merely suggest patterns. Human interpretation is still a crucial aspect to what we do.\n\n\nThe reason why we’re checking for equality of variance (also referred to as homogeneity of variance) is because many statistical tests assume that the spread of the data within different parental populations (in this case, two) is the same.\nIf that is indeed the case, then the data themselves should have equal spread as well.\nThe Shapiro-Wilk test and the Q-Q plots have shown that some of the data might not be normal enough (although in opposite directions!) and so in order to test for equality of variance we will use Levene’s test.\n\ntidyverseRPython\n\n\nThe function we use is levene_test() from the rstatix library.\nIt takes the data in the form of a formula as follows:\n\nrivers %>% \n  levene_test(length ~ river)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  <int> <int>     <dbl> <dbl>\n1     1    66      1.77 0.188\n\n\nThe key bit of information is the p column. This is the p-value (0.1876) for this test.\n\n\nLevene’s test is not included in the default R packages and may require the installation of an additional package called car (Companion to Applied Regression).\nTo install the car package, run the following command in your console:\n\ninstall.packages(\"car\")\n\nAlternatively, go to Tools > Install packages… > Packages, type in car and press Install\nWe can now perform Levene’s test:\n\nleveneTest(length ~ river, data = rivers)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1  1.7732 0.1876\n      66               \n\n\nIgnore any warning you might get about coercion to factors (the test needs to create grouped variables to work and R versions from 4.x onwards do not read in the data as factors).\nThe key bit of information is the 3rd line under the text Pr(>F). This is the p-value for this test.\n\n\nLevene’s test is included in the stats module in scipy. It requires two vectors as input, so we need to subset our data for each river:\n\naripo = rivers_py.query('river == \"Aripo\"')[\"length\"]\nguanapo = rivers_py.query('river == \"Guanapo\"')[\"length\"]\n\nstats.levene(aripo, guanapo)\n\nLeveneResult(statistic=1.7731837331911642, pvalue=0.18756940068805075)\n\n\n\n\n\nThe p-value tells us the probability of observing these two samples if they come from distributions with the same variance. As this probability is greater than our arbitrary significance level of 0.05 then we can be somewhat confident that the necessary assumptions for carrying out Student’s t-test on these two samples was valid. (Once again woohoo!)\n\nBartlett’s test\nIf we had wanted to carry out Bartlett’s test (i.e. if the data had been sufficiently normally distributed) then we would have done:\n\ntidyverseRPython\n\n\nHere we use bartlett.test() from base R. Surprisingly, the rstatix package does not have a built-in equivalent.\nIf we wanted to get the output of the Bartlett test into a tidy format, we could do the following, where we take the rivers data set and pipe it to the bartlett.test() function. Note that we need to define the data using a dot (.), because the first input into bartlett.test() is not the data. We then pipe the output to the tidy() function, which is part of the broom library, which kindly converts the output into a tidy format. Handy!\n\n# load the broom package\nlibrary(broom)\n\n# perform Bartlett's test on the data and tidy\nrivers %>% \n  bartlett.test(length ~ river,\n                data = .) %>% \n  tidy()\n\n# A tibble: 1 × 4\n  statistic p.value parameter method                                   \n      <dbl>   <dbl>     <dbl> <chr>                                    \n1      4.47  0.0344         1 Bartlett test of homogeneity of variances\n\n\n\n\n\nbartlett.test(length ~ river, data = rivers_r)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  length by river\nBartlett's K-squared = 4.4734, df = 1, p-value = 0.03443\n\n\nThe relevant p-value is given on the 3rd line.\n\n\nWe’ve already subset our data into guanapo and aripo, vectors that contain our data.\n\nstats.bartlett(aripo, guanapo)\n\nBartlettResult(statistic=4.4734366516240165, pvalue=0.03442568304468286)"
  },
  {
    "objectID": "cs1_practical_two-sample-t-test.html#implement-and-interpret-the-test",
    "href": "cs1_practical_two-sample-t-test.html#implement-and-interpret-the-test",
    "title": "Student’s t-test",
    "section": "Implement and interpret the test",
    "text": "Implement and interpret the test\nIn this case we’re ignoring the fact that the data are not normal enough, according to the Shapiro-Wilk test. However, this is not entirely naughty, because the sample sizes are pretty large and the t-test is also pretty robust in this case, we can perform a t-test. Remember, this is only allowed because the variances of the two groups (Aripo and Guanapo) are equal.\nPerform a two-sample, two-tailed, t-test:\n\ntidyverseRPython\n\n\n\n# two-sample, two-tailed t-test\nrivers %>% \n  t_test(length ~ river,\n         alternative = \"two.sided\",\n         var.equal = TRUE)\n\n# A tibble: 1 × 8\n  .y.    group1 group2     n1    n2 statistic    df        p\n* <chr>  <chr>  <chr>   <int> <int>     <dbl> <dbl>    <dbl>\n1 length Aripo  Guanapo    39    29      3.84    66 0.000275\n\n\nHere we do the following:\n\nWe take the data set and pipe it to the t_test() function\nThe t_test() function takes the formula in the format variable ~ category\nAgain the alternative is two.sided because we have no prior knowledge about whether the alternative should be greater or less\nThe last argument says whether the variance of the two samples can be assumed to be equal (Student’s t-test) or unequal (Welch’s t-test)\n\nSo, how do we interpret these results?\n\nThe first 5 columns give you information on the variable (.y.), groups and sample size of each group\nThe statistic column gives the t-value of 3.8433 (we need this for reporting)\nThe df column tell us there are 66 degrees of freedom (we need this for reporting)\nThe p column gives us a p-value of 0.0002754\n\n\n\n\nt.test(length ~ river, data = rivers_r,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  length by river\nt = 3.8433, df = 66, p-value = 0.0002754\nalternative hypothesis: true difference in means between group Aripo and group Guanapo is not equal to 0\n95 percent confidence interval:\n 0.9774482 3.0909868\nsample estimates:\n  mean in group Aripo mean in group Guanapo \n             20.33077              18.29655 \n\n\n\nThe first argument must be in the formula format: variables ~ category\nThe second argument must be the name of the data frame\nThe third argument gives the type of alternative hypothesis and must be one of two.sided, greater or less\nThe fourth argument says whether the variance of the two samples can be assumed to be equal (Student’s t-test) or unequal (Welch’s t-test)\n\nSo, how do we interpret the results?\n\nThe 1st line gives the name of the test and the 2nd line reminds you what the data set was called, and what variables were used.\nThe 3rd line contains the three key outputs from the test:\n\nThe calculated t-value is 3.8433 (we need this for reporting)\nThere are 66 degrees of freedom (we need this for reporting)\nThe p-value is 0.0002754.\n\nThe 4th line simply states the alternative hypothesis in terms of the difference between the two sample means (testing if the two sample means are different is equivalent to testing whether the difference in the means is equal to zero).\nThe 5th and 6th lines give the 95th confidence interval (we don’t need to know this here).\nThe 7th, 8th and 9th lines give the sample means for each group (20.33077 in Aripo and 18.29655 in Guanapo) which we found earlier.\n\n\n\n\nstats.ttest_ind(aripo, guanapo,\n                alternative = \"two-sided\",\n                equal_var = True)\n\nTtest_indResult(statistic=3.8432667461726275, pvalue=0.00027544021976337834)\n\n\n\n\n\nAgain, the p-value is what we’re most interested in. Since the p-value is very small (much smaller than the standard significance level) we choose to say “that it is very unlikely that these two samples came from the same parent distribution and as such we can reject our null hypothesis” and state that:\n\nA Student’s t-test indicated that the mean body length of male guppies in the Guanapo river (18.29 mm) differs significantly from the mean body length of male guppies in the Aripo river (20.33 mm) (t = 3.8433, df = 66, p = 0.0003).\n\n\nNow there’s a conversation starter."
  },
  {
    "objectID": "cs1_practical_two-sample-t-test.html#exercise-turtles",
    "href": "cs1_practical_two-sample-t-test.html#exercise-turtles",
    "title": "Student’s t-test",
    "section": "Exercise: Turtles",
    "text": "Exercise: Turtles\nThis exercise explores serum cholesterol concentrations in turtles.\nUsing the following data, test the null hypothesis that male and female turtles have the same mean serum cholesterol concentrations.\n\n\n\n\n \n  \n    id \n    Male \n    Female \n  \n \n\n  \n    1 \n    220.1 \n    NA \n  \n  \n    2 \n    218.6 \n    NA \n  \n  \n    3 \n    229.6 \n    NA \n  \n  \n    4 \n    228.8 \n    NA \n  \n  \n    5 \n    222.0 \n    NA \n  \n  \n    6 \n    224.1 \n    NA \n  \n  \n    7 \n    226.5 \n    NA \n  \n  \n    8 \n    NA \n    223.4 \n  \n  \n    9 \n    NA \n    221.5 \n  \n  \n    10 \n    NA \n    230.2 \n  \n  \n    11 \n    NA \n    224.3 \n  \n  \n    12 \n    NA \n    223.8 \n  \n  \n    13 \n    NA \n    230.8 \n  \n\n\n\n\n\n\nCreate a tidy data frame and save as a .csv file\nWrite down the null and alternative hypotheses\nImport the data\nSummarise and visualise the data\nCheck your assumptions (normality and variance) using appropriate tests and plots\nPerform a two-sample t-test\nWrite down a sentence that summarises the results that you have found\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nData\nWe’ll stop asking you to manually create your own data files soon, but it’s meant to get you to think about how to record your data. If we’re using a tidy data format, then each variable (thing that you measure) is in its own column. Each observation has its own row.\nThis means that if you would restructure the data from above it would look like this:\n\n\n\n\nturtle\n\n# A tibble: 13 × 2\n   serum sex   \n   <dbl> <chr> \n 1  220. Male  \n 2  219. Male  \n 3  230. Male  \n 4  229. Male  \n 5  222  Male  \n 6  224. Male  \n 7  226. Male  \n 8  223. Female\n 9  222. Female\n10  230. Female\n11  224. Female\n12  224. Female\n13  231. Female\n\n\n\n\nHypotheses\n\\(H_0\\) : male mean \\(=\\) female mean\n\\(H_1\\) : male mean \\(\\neq\\) female mean\n\n\nLoad, summarise and visualise data\nLet’s load the data (I’ve created the .csv file earlier) and explore our data a bit more before we dive into the statistics.\n\ntidyverseRPython\n\n\n\n# load the data\nturtle <- read_csv(\"data/CS1-turtle.csv\")\n\nRows: 13 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (1): serum\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# and have a look\nturtle\n\n# A tibble: 13 × 2\n   serum sex   \n   <dbl> <chr> \n 1  220. Male  \n 2  219. Male  \n 3  230. Male  \n 4  229. Male  \n 5  222  Male  \n 6  224. Male  \n 7  226. Male  \n 8  223. Female\n 9  222. Female\n10  230. Female\n11  224. Female\n12  224. Female\n13  231. Female\n\n\nLet’s summarise the data (although a visualisation is probably much easier to work with):\n\n# create summary statistics for each group\nturtle %>% \n  group_by(sex) %>% \n  get_summary_stats(type = \"common\")\n\n# A tibble: 2 × 11\n  sex    variable     n   min   max median   iqr  mean    sd    se    ci\n  <chr>  <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Female serum        6  222.  231.   224.  5.22  226.  3.87  1.58  4.06\n2 Male   serum        7  219.  230.   224.  6.6   224.  4.26  1.61  3.94\n\n\nand visualise the data:\n\n# visualise the data\nturtle %>% \n  ggplot(aes(x = sex, y = serum)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n# load the data\nturtle_r <- read.csv(\"data/CS1-turtle.csv\")\n\n# and have a look\nhead(turtle_r)\n\n  serum  sex\n1 220.1 Male\n2 218.6 Male\n3 229.6 Male\n4 228.8 Male\n5 222.0 Male\n6 224.1 Male\n\n\nand visualise the data:\n\n# visualise the data\nboxplot(serum ~ sex , data = turtle_r)\n\n\n\n\n\n\n\nturtle_py = pd.read_csv(\"data/CS1-turtle.csv\")\n\nturtle_py.describe()\n\n            serum\ncount   13.000000\nmean   224.900000\nstd      3.978274\nmin    218.600000\n25%    222.000000\n50%    224.100000\n75%    228.800000\nmax    230.800000\n\n\nand visualise the data:\n\n(\n  ggplot(turtle_py, aes(x = \"sex\",\n                        y = \"serum\"))\n  + geom_boxplot()\n)\n\n\n\n\n\n\n\nAs always we use the plot and summary to assess three things:\n\nDoes it look like we’ve loaded the data in correctly?\n\nWe have two groups and the extreme values of our plots seem to match with our data set, so I’m happy that we haven’t done anything massively wrong here.\n\nDo we think that there is a difference between the two groups?\n\nWe need the result of the formal test to make sense given the data, so it’s important to develop a sense of what we think is going to happen here. Whilst the ranges of the two groups suggests that the Female serum levels might be higher than the males when we look at things more closely we realise that isn’t the case. The box plot shows that the median values of the two groups is virtually identical and this is backed up by the summary statistics we calculated: the medians are both about 224.1, and the means are fairly close too (225.7 vs 224.2). Based on this, and the fact that there are only 13 observations in total I would be very surprised if any test came back showing that there was a difference between the groups.\n\nWhat do we think about assumptions?\n\nNormality looks a bit worrying: whilst the Male group appears nice and symmetric (and so might be normal), the Female group appears to be quite skewed (since the median is much closer to the bottom than the top). We’ll have to look carefully at the more formal checks to decided whether we think the data are normal enough for us to use a t-test.\nHomogeneity of variance. At this stage the spread of the data within each group looks similar, but because of the potential skew in the Female group we’ll again want to check the assumptions carefully.\n\n\n\n\nAssumptions\nNormality\nLet’s look at the normality of each of the groups separately. There are several ways of getting at the serum values for Male and Female groups separately. All of them come down to splitting the data. Afterwards we use the Shapiro-Wilk (‘formal’ test), followed by Q-Q plots (much more informative).\n\ntidyverseRPython\n\n\n\n# perform Shapiro-Wilk test on each group\nturtle %>% \n  group_by(sex) %>% \n  shapiro_test(serum)\n\n# A tibble: 2 × 4\n  sex    variable statistic     p\n  <chr>  <chr>        <dbl> <dbl>\n1 Female serum        0.842 0.135\n2 Male   serum        0.944 0.674\n\n\n\n\nWe can use the unstack() function to split the data, then access the relevant values.\n\nuns_turtle_r <- unstack(turtle_r, serum ~ sex)\n\nuns_turtle_r\n\n$Female\n[1] 223.4 221.5 230.2 224.3 223.8 230.8\n\n$Male\n[1] 220.1 218.6 229.6 228.8 222.0 224.1 226.5\n\n\nYou can see that the data has been split by sex.\n\nshapiro.test(uns_turtle_r$Male)\n\n\n    Shapiro-Wilk normality test\n\ndata:  uns_turtle_r$Male\nW = 0.94392, p-value = 0.6743\n\nshapiro.test(uns_turtle_r$Female)\n\n\n    Shapiro-Wilk normality test\n\ndata:  uns_turtle_r$Female\nW = 0.84178, p-value = 0.1349\n\n\n\n\n\nturtle_male = turtle_py.query('sex == \"Male\"')[\"serum\"]\nturtle_female = turtle_py.query('sex == \"Female\"')[\"serum\"]\n\n\nstats.shapiro(turtle_male)\n\nShapiroResult(statistic=0.9439237713813782, pvalue=0.6742751598358154)\n\nstats.shapiro(turtle_female)\n\nShapiroResult(statistic=0.8417852520942688, pvalue=0.1348712146282196)\n\n\n\n\n\nThe p-values for both Shapiro-Wilk tests are non-significant which suggests that the data are normal enough. This is a bit surprising given what we saw in the box plot but there are two bits of information that we can use to reassure us.\n\nThe p-value for the Female group is smaller than for the Male group (suggesting that the Female group is closer to being non-normal than the Male group) which makes sense based on our visual observations.\nThe Shapiro-Wilk test is generally quite relaxed about normality for small sample sizes (and notoriously strict for very large sample sizes). For a group with only 6 data points in it, the data would actually have to have a really, really skewed distribution. Given that the Female group only has 6 data points in it, it’s not too surprising that the Shapiro-Wilk test came back saying everything is OK.\n\nGiven these caveats of the Shapiro-Wilk test (I’ll stop mentioning them now, I think I’ve made my opinion clear ;)), let’s look at the Q-Q plots.\n\ntidyverseRPython\n\n\n\n# create Q-Q plots for both groups\nturtle %>% \n  ggplot(aes(sample = serum)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  facet_wrap(facets = vars(sex))\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nqqnorm(uns_turtle_r$Female, main = \"Female\")\nqqline(uns_turtle_r$Female, col = \"red\")\nqqnorm(uns_turtle_r$Male, main = \"Male\")\nqqline(uns_turtle_r$Male, col = \"red\")\n\n\n\n\n\n\n\n# create Q-Q plots for both groups\n(\n  ggplot(turtle_py, aes(sample = \"serum\"))\n  + stat_qq()\n  + stat_qq_line(colour = \"red\")\n  + facet_wrap(\"sex\")\n)\n\n\n\n\n\n\n\nThe results from the Q-Q plots echo what we’ve already seen from the Shapiro-Wilk analyses. The normality of the data in the Male group doesn’t look too bad whereas the those in the Female group looks somewhat dodgy.\nOverall, the assumption of normality of the data doesn’t appear to be very well met at all, but we do have to bear in mind that there are only a few data points in each group and we might just be seeing this pattern in the data due to random chance rather than because the underlying populations are actually not normally distributed. Personally, though I’d edge towards non-normal here.\nHomogeneity of Variance\nIt’s not clear whether the data are normal or not, so it isn’t clear which test to use here. The sensible approach is to do both and hope that they agree (fingers crossed!). Or err on the side of caution and assume they are not normal, but potentially throwing away statistical power (more on that later).\n\ntidyverseRPython\n\n\nBartlett’s test gives us:\n\n# perform Bartlett's test\nbartlett.test(serum ~ sex,\n              data = turtle)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  serum by sex\nBartlett's K-squared = 0.045377, df = 1, p-value = 0.8313\n\n\nand Levene’s test gives us:\n\n# perform Levene's test\nturtle %>% \n  levene_test(serum ~ sex)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  <int> <int>     <dbl> <dbl>\n1     1    11     0.243 0.631\n\n\n\n\nBartlett’s test gives us:\n\nbartlett.test(serum ~ sex, turtle_r)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  serum by sex\nBartlett's K-squared = 0.045377, df = 1, p-value = 0.8313\n\n\nand Levene’s test gives us:\n\n# load if needed\n# library(car)\n\nleveneTest(serum ~ sex, turtle_r)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1  0.2434 0.6315\n      11               \n\n\n\n\nBartlett’s test gives us:\n\nstats.bartlett(turtle_male, turtle_female)\n\nBartlettResult(statistic=0.0453770725135282, pvalue=0.8313121829253811)\n\n\nand Levene’s test gives us:\n\nstats.levene(turtle_male, turtle_female)\n\nLeveneResult(statistic=0.24341796609304578, pvalue=0.6314503568954707)\n\n\n\n\n\nThe good news is that both Levene and Bartlett agree that there is homogeneity of variance between the two groups (thank goodness, that’s one less thing to worry about!).\nOverall, what this means is that we’re not too sure about normality, but that homogeneity of variance is pretty good.\n\n\nImplement two-sample t-test\nBecause of the result of the Bartlett test I know that I can carry out a two-sample Student’s t-test. If the variances between the two groups were not equal, then we’d have to perform Welch’s t-test.\n\ntidyverseRPython\n\n\n\n# perform two-sample t-test\nturtle %>% \n  t_test(serum ~ sex,\n         alternative = \"two.sided\",\n         var.equal = TRUE)\n\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic    df     p\n* <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl> <dbl>\n1 serum Female Male       6     7     0.627    11 0.544\n\n\n\n\n\nt.test(serum ~ sex,\n       data = turtle_r,\n       alternative = \"two.sided\",\n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  serum by sex\nt = 0.62681, df = 11, p-value = 0.5436\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -3.575759  6.423378\nsample estimates:\nmean in group Female   mean in group Male \n            225.6667             224.2429 \n\n\n\n\n\nstats.ttest_ind(turtle_male, turtle_female,\n                alternative = \"two-sided\",\n                equal_var = True)\n\nTtest_indResult(statistic=-0.6268108404512706, pvalue=0.543572996867541)\n\n\n\n\n\nWith a p-value of 0.544, this test tells me that there is insufficient evidence to suggest that the means of the two groups are different. A suitable summary sentence would be:\n\nA Student’s two-sample t-test indicated that the mean serum cholesterol level did not differ significantly between Male and Female turtles (t = 0.627, df = 11, p = 0.544).\n\n\n\n\nDiscussion\nIn reality, because of the ambiguous normality assumption assessment, for this data set I would actually carry out two different tests; the two-sample t-test with equal variance and the Mann-Whitney U test. If both of them agreed then it wouldn’t matter too much which one I reported (I’d personally report both with a short sentence to say that I’m doing that because it wasn’t clear whether the assumption of normality had or had not been met), but it would be acceptable to report just one."
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html",
    "href": "cs1_practical_one-sample-wilcoxon.html",
    "title": "Wilcoxon signed-rank test",
    "section": "",
    "text": "This test also considers a single sample, however for this test (in contrast to the one sample t-test) we don’t have to assume that the parent distribution is normally distributed. We do still need the parent distribution (and consequently the sample) to be symmetric though. In this test we look to see if the median of the parent distributions differs significantly from a given hypothesised value (in contrast with the t-test that looks at the mean)."
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html#libraries-and-functions",
    "href": "cs1_practical_one-sample-wilcoxon.html#libraries-and-functions",
    "title": "Wilcoxon signed-rank test",
    "section": "Libraries and functions",
    "text": "Libraries and functions\n\ntidyverseRPython\n\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nlibrary(tidyverse)\nA collection of R packages designed for data science\n\n\nlibrary(rstatix)\nConverts base R stats functions to a tidyverse-friendly format. Also contains extra functionality that we’ll use.\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nrstatix::wilcox_test()\nPerforms one and two sample Wilcoxon tests.\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nwilcoxon.test()\nPerforms one- and two-sample Wilcoxon tests on vectors of data; the latter is also known as ‘Mann-Whitney’ test.\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nplotnine\nThe Python equivalent of ggplot2.\n\n\npandas\nA Python data analysis and manipulation tool.\n\n\nscipy.stats\nA Python module containing statistical functions.\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nscipy.stats.wilcoxon()\nCalculate the Wilcoxon signed-rank test."
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html#data-and-hypotheses",
    "href": "cs1_practical_one-sample-wilcoxon.html#data-and-hypotheses",
    "title": "Wilcoxon signed-rank test",
    "section": "Data and hypotheses",
    "text": "Data and hypotheses\nAgain, we use the fishlength data set. The one-sample Wilcoxon signed-rank test allows to see if the median body length is different from a specified value. Here we want to test whether the data support the hypothesis that the median body is actually 20 mm. The following null and alternative hypotheses are very similar to those used for the one sample t-test:\n\n\\(H_0\\): The median body length is equal to 20 mm (\\(\\mu =\\) 20).\n\\(H_1\\): The median body length is not equal to 20 mm (\\(\\mu \\neq\\) 20).\n\nWe will use a one-sample, two-tailed Wilcoxon signed-rank test to see if we should reject the null hypothesis or not."
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html#summarise-and-visualise",
    "href": "cs1_practical_one-sample-wilcoxon.html#summarise-and-visualise",
    "title": "Wilcoxon signed-rank test",
    "section": "Summarise and visualise",
    "text": "Summarise and visualise\nWe did this before in the previous section, nothing really should have changed between now and then (if it has then you’re not off to a good start on this practical!)"
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html#assumptions",
    "href": "cs1_practical_one-sample-wilcoxon.html#assumptions",
    "title": "Wilcoxon signed-rank test",
    "section": "Assumptions",
    "text": "Assumptions\nIn order to use a one-sample Wilcoxon rank-sum test for this analysis (and for the results to be strictly valid) we have to make two assumptions:\n\nThe data are distributed symmetrically around the median\nEach data point in the sample is independent of the others. This is the same as for the t-test and is a common feature of nearly all statistical tests. Lack of independence in your data is really tough to deal with (if not impossible) and a large part of proper experimental design is ensuring this.\n\nWhilst there are formal statistical tests for symmetry we will opt for a simple visual inspection using both a box plot and a histogram.\nPlot a histogram and a box plot of the data:\n\ntidyverseRPython\n\n\nLet’s first determine the median, so we can use that to compare our data to.\n\n# determine the median\nmedian_fishlength <- fishlengthDF %>% \n  summarise(median_fishlength = median(length)) %>% \n  pull(median_fishlength)\n\n\n# create a histogram\nfishlengthDF %>% \n  ggplot(aes(x = length)) +\n  geom_histogram(bins = 10) +\n  geom_vline(xintercept = median_fishlength,\n             colour = \"red\")\n\n\n\n# create box plot\nfishlengthDF %>% \n  ggplot(aes(y = length)) +\n  geom_boxplot()\n\n\n\n\n\n\nLet’s first determine the median, so we can use that to compare our data to.\n\n# determine the median\nmedian_fishlength <- median(fishlength_r)\n\n\nhist(fishlength_r, breaks = 10)\nabline(v = median_fishlength,\n       col = \"red\")\n\nboxplot(fishlength_r)\n\nYou get the following plots:\n\n\n\n\n\n\n\nLet’s first determine the median, so we can use that to compare our data to.\n\nmedian_fishlength = fishlength_py.length.median()\n\n\n# create a histogram\n(\nggplot(fishlength_py, aes(x = \"length\"))\n+ geom_histogram(bins = 10)\n+ geom_vline(xintercept = median_fishlength,\n             colour = \"red\")\n)\n\n\n\n(\n# create box plot\nggplot(fishlength_py,\naes(x = 1,\n    y = 'length'))\n+ geom_boxplot()\n)\n\n\n\n\n\n\n\nHere we can see that whilst the distribution isn’t perfectly symmetric, neither is it heavily skewed to the left or right and we can make the call that the distribution is symmetric enough for us to be happy with the results of the test."
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html#implement-and-interpret-the-test",
    "href": "cs1_practical_one-sample-wilcoxon.html#implement-and-interpret-the-test",
    "title": "Wilcoxon signed-rank test",
    "section": "Implement and interpret the test",
    "text": "Implement and interpret the test\nPerform a one-sample, two-tailed Wilcoxon signed-rank test:\n\ntidyverseRPython\n\n\n\nfishlengthDF %>% \n  wilcox_test(length ~ 1,\n              mu = 20,\n              alternative = \"two.sided\")\n\n# A tibble: 1 × 6\n  .y.    group1 group2         n statistic       p\n* <chr>  <chr>  <chr>      <int>     <dbl>   <dbl>\n1 length 1      null model    29      67.5 0.00122\n\n\nThe syntax is identical to the one-sample t-test we carried out earlier.\n\nthe formula, here we give it length ~ 1 to indicate it is a one-sample test on length\nthe mu is the median to be tested under the null hypothesis, here it is 20\nthe alternative argument gives the type of alternative hypothesis and must be one of two.sided, greater or less. We have no prior assumptions on whether the alternative median fish length would be greater or less than 20, so we choose two.sided.\n\n\nthe statistic column gives us the t-statistic of 67.5 (we’ll need this for reporting)\nthe n column gives us the sample size of 29\nthe p column gives us the p-value of 0.0012\n\n\n\n\nwilcox.test(fishlength_r, \n            mu = 20,\n            alternative = \"two.sided\")\n\nWarning in wilcox.test.default(fishlength_r, mu = 20, alternative =\n\"two.sided\"): cannot compute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  fishlength_r\nV = 67.5, p-value = 0.001222\nalternative hypothesis: true location is not equal to 20\n\n\nThe syntax is identical to the one-sample t-test we carried out earlier.\n\nThe first argument must be a numerical vector of data values.\nThe second argument must be a number and is the median to be tested under the null hypothesis.\nThe third argument gives the type of alternative hypothesis and must be one of two.sided, greater or less.\nThe first two lines give a warning (not an error) message regarding the implementation of this test. This can be safely ignored in this case as the p-value is so small, but essentially, it’s letting you know that some of the data values are identical to each other. This is not supposed to happen as we should be dealing with continuous data for this test, but in practice it’s not something that we need to worry ourselves with.\nThe 3rd line gives the name of the test and the 4th line reminds you what the data set was called\nThe 5th line contains the two key outputs from the test:\n\nThe calculated statistic is 67.5 (we’ll need this for reporting)\nThe p-value is 0.001222.\n\nThe 6th line simply states the alternative hypothesis\n\n\n\n\nstats.wilcoxon(fishlength_py.length - 20,\n               alternative = \"two-sided\")\n\nWilcoxonResult(statistic=67.5, pvalue=0.0011760820729428206)\n\n\nThe syntax is similar to what we did earlier:\n\nThe 1st argument we give to the wilcoxon() function is an array of the differences between our data points and the median to be tested under the null hypothesis, i.e. our data points (fishlength_py.length) minus the test median (20, in this case).\nThe 2nd argument gives us the type of alternative hypothesis and must be one of “two-sided”, “larger”, or “smaller”. This is in contrast to the 1-sample t-test in Python that can only mange two-sided alternative hypotheses.\n\n\n\n\nAgain, the p-value is what we’re most interested in. It gives the probability of us getting a sample such as ours if the null hypothesis were actually true. So, in this case since our p-value is less than 0.05 we can reject our null hypothesis and state that:\n\nA one-sample Wilcoxon signed-rank test indicated that the median body length of male guppies (\\(\\mu\\) = 18.8 mm) differs significantly from 20 mm (V = 67.5, n = 29, p = 0.0012).\n\n\n\nThe above sentence is an adequate concluding statement for this test and is what we would write in any paper or report. Note that we have included (in brackets) information on the median value of the group (\\(\\mu\\) = 18.8 mm), the test statistic (V = 67.5), the number of observations (n = 29), and the p-value (p = 0.0012)."
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html#exercise-gastric-juices-revisited",
    "href": "cs1_practical_one-sample-wilcoxon.html#exercise-gastric-juices-revisited",
    "title": "Wilcoxon signed-rank test",
    "section": "Exercise: Gastric juices (revisited)",
    "text": "Exercise: Gastric juices (revisited)\nPerforming a Wilcoxon signed-rank test:\n\nAnalyse the drug data set from before using a one-sample Wilcoxon signed-rank test\nDiscuss with a (virtual) neighbour which of the two tests you feel is best suited to the data.\nDoes it matter in this case?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nHypotheses\n\\(H_0\\) : median \\(=\\) 45s\n\\(H_1\\) : median \\(\\neq\\) 45s\n\n\nAssumptions\nFrom the box plot from the previous exercise we already know that the data are symmetric enough for the test to be valid.\n\n\nWilcoxon signed-rank test\nPerforming the test:\n\ntidyverseRPython\n\n\n\ndissolving %>% \n  wilcox_test(dissolving_time ~ 1,\n              mu = 45,\n              alternative = \"two.sided\")\n\n# A tibble: 1 × 6\n  .y.             group1 group2         n statistic     p\n* <chr>           <chr>  <chr>      <int>     <dbl> <dbl>\n1 dissolving_time 1      null model     8        22 0.641\n\n\n\n\n\nwilcox.test(dissolving_r$dissolving_time,\n            mu = 45,\n            alternative = \"two.sided\")\n\n\n    Wilcoxon signed rank exact test\n\ndata:  dissolving_r$dissolving_time\nV = 22, p-value = 0.6406\nalternative hypothesis: true location is not equal to 45\n\n\n\n\n\nstats.wilcoxon(dissolving_py.dissolving_time - 45,\n               alternative = \"two-sided\")\n\nWilcoxonResult(statistic=14.0, pvalue=0.640625)\n\n\n\n\n\n\nA one-sample Wilcoxon-signed rank test indicated that the median dissolving time of the drug is not significantly different from 45 s (V=22, n=8 , p=0.64)\n\n\n\n\n\nDiscussion\nIn terms of choosing between the two test we can see that both meet their respective assumptions and so both tests are valid. In this case both tests also agree in terms of their conclusions i.e. that the average dissolving time (either mean or median) doesn’t differ significantly from the proposed value of 45 s.\n\nSo one answer would be that it doesn’t matter which test you use.\nAnother answer would be that you should pick the test that measures the quantity you’re interested in i.e. if you care about medians then use the Wilcoxon test, whereas if you care about means then use the t-test.\nA final answer would be that, since both test are valid we would prefer to use the test with greater power. t-tests always have more power than Wilcoxon tests (as long as they’re valid) and so we could report that one. (We’ll talk about this in the last session but power is effectively the capacity of a test to detect a significant difference - so more power is better)."
  },
  {
    "objectID": "cs1_practical_one-sample-wilcoxon.html#key-points",
    "href": "cs1_practical_one-sample-wilcoxon.html#key-points",
    "title": "Wilcoxon signed-rank test",
    "section": "Key points",
    "text": "Key points\n\n\n\n\n\n\nNote\n\n\n\n\nOne-sample tests are used when you have a single sample of continuous data\nThe t-test assumes that the data are normally distributed and independent of each other\nThe Wilcoxon signed-rank test does not assume a normal distribution, but does require independent samples and symmetry around the median\nA good way of assessing the assumption of normality is by checking the data against a Q-Q plot"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Core statistics",
    "section": "",
    "text": "Authors and contributors: Martin van Rongen, Matt Castle, Rob Nicholls, Holly Pavey, Vicki Hodgson\nWelcome to Core statistics!\nThese sessions are intended to enable you to perform core data analysis techniques appropriately and confidently using R.\nThey are not a “how to mindlessly use a stats program” course!"
  },
  {
    "objectID": "index.html#core-aims",
    "href": "index.html#core-aims",
    "title": "Welcome to Core statistics",
    "section": "Core aims",
    "text": "Core aims\nThere are several things that we try to achieve during this course.\n\n\n\n\n\n\nCourse aims\n\n\n\nTo know what to do when presented with an arbitrary data set e.g.\n\nKnow what data analysis techniques are available\nKnow which ones are allowable\nBe able to carry these out and understand the results"
  },
  {
    "objectID": "index.html#core-topics",
    "href": "index.html#core-topics",
    "title": "Welcome to Core statistics",
    "section": "Core topics",
    "text": "Core topics\n\nSimple hypothesis testing\nCategorical predictor variables\nContinuous predictors\nTwo predictor variables\nMultiple predictor variables\nPower analysis"
  },
  {
    "objectID": "index.html#practicals",
    "href": "index.html#practicals",
    "title": "Welcome to Core statistics",
    "section": "Practicals",
    "text": "Practicals\nEach practical document is divided up into various sections. In each section there will be some explanatory text which should help you to understand what is going on and what you’re trying to achieve. There may be a list of commands relevant to that section which will be displayed in boxes like this:\n\n\n\n\n\n\nConditional operators\n\n\n\nTo set filtering conditions, use the following relational operators:\n\n> is greater than\n>= is greater than or equal to\n< is less than\n<= is less than or equal to\n== is equal to\n!= is different from\n%in% is contained in\n\nTo combine conditions, use the following logical operators:\n\n& AND\n| OR"
  },
  {
    "objectID": "index.html#index-datasets",
    "href": "index.html#index-datasets",
    "title": "Welcome to Core statistics",
    "section": "Datasets",
    "text": "Datasets\nThis course uses various data sets. The easiest way of accessing these is by creating an R-project in RStudio. Then download the data folder here by right-clicking on the link and Save as…. Next unzip the file and copy it into your working directory. Your data should then be accessible via <working-directory-name>/data/."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "More info later."
  },
  {
    "objectID": "cs1_practical_two-sample-mann-whitney.html",
    "href": "cs1_practical_two-sample-mann-whitney.html",
    "title": "Mann-Whitney U test",
    "section": "",
    "text": "This test also compares two samples, however for this test (in contrast to Student’s t-test) we don’t have to assume that the parent distributions are normally distributed. In order to compare the medians of the two groups we do still need the parent distributions (and consequently the samples) to both have the same shape and variance. In this test we look to see if the medians of the two parent distributions differ significantly from each other."
  },
  {
    "objectID": "cs1_practical_two-sample-mann-whitney.html#libraries-and-functions",
    "href": "cs1_practical_two-sample-mann-whitney.html#libraries-and-functions",
    "title": "Mann-Whitney U test",
    "section": "Libraries and functions",
    "text": "Libraries and functions\n\ntidyverseRPython\n\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nlibrary(tidyverse)\nA collection of R packages designed for data science\n\n\nlibrary(rstatix)\nConverts base R stats functions to a tidyverse-friendly format. Also contains extra functionality that we’ll use.\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nrstatix::wilcox_test()\nPerforms one- and two-sample Wilcoxon tests on vectors of data; the latter is also known as ‘Mann-Whitney’ test\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nwilcox.test()\nPerforms one- and two-sample Wilcoxon tests on vectors of data; the latter is also known as ‘Mann-Whitney’ test\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\npandas\nA Python data analysis and manipulation tool.\n\n\nscipy.stats\nA Python module containing statistical functions.\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\npandas.DataFrame.pivot()\nReturn reshaped DataFrame organised by given index / column values.\n\n\nscipy.stats.mannwhitneyu()\nCalculate the Mann-Whitney U test"
  },
  {
    "objectID": "cs1_practical_two-sample-mann-whitney.html#data-and-hypotheses",
    "href": "cs1_practical_two-sample-mann-whitney.html#data-and-hypotheses",
    "title": "Mann-Whitney U test",
    "section": "Data and hypotheses",
    "text": "Data and hypotheses\nAgain, we use the rivers data set. We want to test whether the median body length of male guppies differs between samples. We form the following null and alternative hypotheses:\n\n\\(H_0\\): The difference in median body length between the two groups is 0 \\((\\mu A - \\mu G = 0)\\)\n\\(H_1\\): The difference in median body length between the two groups is not 0 \\((\\mu A - \\mu G \\neq 0)\\)\n\nWe use a two-tailed Mann-Whitney U test to see if we can reject the null hypothesis."
  },
  {
    "objectID": "cs1_practical_two-sample-mann-whitney.html#summarise-and-visualise",
    "href": "cs1_practical_two-sample-mann-whitney.html#summarise-and-visualise",
    "title": "Mann-Whitney U test",
    "section": "Summarise and visualise",
    "text": "Summarise and visualise\nWe did this in the previous section."
  },
  {
    "objectID": "cs1_practical_two-sample-mann-whitney.html#assumptions",
    "href": "cs1_practical_two-sample-mann-whitney.html#assumptions",
    "title": "Mann-Whitney U test",
    "section": "Assumptions",
    "text": "Assumptions\nWe have checked these previously."
  },
  {
    "objectID": "cs1_practical_two-sample-mann-whitney.html#implement-and-interpret-the-test",
    "href": "cs1_practical_two-sample-mann-whitney.html#implement-and-interpret-the-test",
    "title": "Mann-Whitney U test",
    "section": "Implement and interpret the test",
    "text": "Implement and interpret the test\nPerform a two-tailed, Mann-Whitney U test:\n\ntidyverseRPython\n\n\n\nrivers %>% \n  wilcox_test(length ~ river,\n              alternative = \"two.sided\")\n\n# A tibble: 1 × 7\n  .y.    group1 group2     n1    n2 statistic        p\n* <chr>  <chr>  <chr>   <int> <int>     <dbl>    <dbl>\n1 length Aripo  Guanapo    39    29       841 0.000646\n\n\n\nThe first argument must be in the formula format: variable ~ category\nThe second argument gives the type of alternative hypothesis and must be one of two.sided, greater or less\n\nYou may get a warning message in the console stating cannot compute exact p-value with ties. This just means that some of the data points have exactly the same value which affects the internal mathematics slightly. However, given that the p-value is so very small, this is not something that we need to worry about.\n\nThe first 5 columns give you information on the variable (.y.), groups and sample size of each group\nThe statistic column gives the t-value of 841 (we need this for reporting)\nThe p column gives us a p-value of 0.0006464.\n\n\n\n\nwilcox.test(length ~ river, data = rivers_r,\n            alternative = \"two.sided\")\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  length by river\nW = 841, p-value = 0.0006464\nalternative hypothesis: true location shift is not equal to 0\n\n\nYou may get a warning message in the console stating cannot compute exact p-value with ties. This just means that some of the data points have exactly the same value which affects the internal mathematics slightly. However, given that the p-value is so very small, this is not something that we need to worry about.\nAfter the warning message:\n\nThe 1st line gives the name of the test and the 2nd line reminds you what the dataset was called, and what variables were used\nThe 3rd line contains the two key outputs from the test:\n\nThe calculated W-value is 841 (we’ll use this in reporting)\nThe p-value is 0.0006464.\n\nThe 4th line simply states the alternative hypothesis in terms of the difference between the two sample medians in that if there were a difference then one distribution would be shifted relative to the other.\n\n\n\nBefore we can implement the Mann-Whitney U test, we need to reformat our data a bit.\nThe stats.mannwhitneyu() function requires the numerical input for the two groups it needs to compare.\nThe easiest way is to reformat our data from the long format where all the data are stacked on top of one another to the wide format, where the length values are in separate columns for the two rivers.\nWe can do this with the pd.pivot() function. We save the output in a new object and then access the values as required. It keeps all the data separate, meaning that there will be missing values NaN in this format. The stats.mannwhitneyu() function doesn’t ignore missing values by default and we can specify this in the nan_policy, by setting this argument to omit.\n\n# reformat the data into a 'wide' format\nrivers_py_wide = pd.pivot(rivers_py,\n                          columns = 'river',\n                          values = 'length')\n      \n# have a look at the format\nrivers_py_wide.head()\n\nriver  Aripo  Guanapo\n0        NaN     19.1\n1        NaN     23.3\n2        NaN     18.2\n3        NaN     16.4\n4        NaN     19.7\n\n\n\n# perform the Mann-Whitney U test\n# ignoring the missing values\nstats.mannwhitneyu(rivers_py_wide['Aripo'],\n                   rivers_py_wide['Guanapo'],\n                   nan_policy = 'omit')\n\nMannwhitneyuResult(statistic=841.0, pvalue=0.0006463668392349246)\n\n\n\n\n\nGiven that the p-value is less than 0.05 we can reject the null hypothesis at this confidence level. Again, the p-value on the 3rd line is what we’re most interested in. Since the p-value is very small (much smaller than the standard significance level) we choose to say “that it is very unlikely that these two samples came from the same parent distribution and as such we can reject our null hypothesis”.\nTo put it more completely, we can state that:\n\nA Mann-Whitney test indicated that the median body length of male guppies in the Guanapo river (18.8 mm) differs significantly from the median body length of male guppies in the Aripo river (20.1 mm) (W = 841, p = 0.0006)."
  },
  {
    "objectID": "cs1_practical_two-sample-mann-whitney.html#exercise-turtles-revisited",
    "href": "cs1_practical_two-sample-mann-whitney.html#exercise-turtles-revisited",
    "title": "Mann-Whitney U test",
    "section": "Exercise: Turtles (revisited)",
    "text": "Exercise: Turtles (revisited)\nAnalyse the turtle data set from before using a Mann-Whitney U test.\nWe follow the same process as with Student’s t-test.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nHypotheses\n\\(H_0\\) : male median \\(=\\) female median\n\\(H_1\\) : male median \\(\\neq\\) female median\n\n\nSummarise and visualise\nThis is the same as before.\n\n\nAssumptions\nWe’ve already checked that the variances of the two groups are similar, so we’re OK there. Whilst the Mann-Whitney U test doesn’t require normality or symmetry of distributions it does require that the distributions have the same shape. In this example, with just a handful of data points in each group, it’s quite hard to make this call one way or another. My advice in this case would be say that unless it’s obvious that the distributions are very different we can just allow this assumption to pass, and you’re only going see obvious differences in distribution shape when you have considerably more data points than we have here.\n\n\nCarry out a Mann-Whitney test\n\ntidyverseRPython\n\n\n\nturtle %>% \n  wilcox_test(serum ~ sex,\n              alternative = \"two.sided\")\n\n# A tibble: 1 × 7\n  .y.   group1 group2    n1    n2 statistic     p\n* <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl>\n1 serum Female Male       6     7        26 0.534\n\n\n\n\n\nwilcox.test(serum ~ sex,\n            data = turtle_r,\n            alternative = \"two.sided\")\n\n\n    Wilcoxon rank sum exact test\n\ndata:  serum by sex\nW = 26, p-value = 0.5338\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n# reformat the data into a 'wide' format\nturtle_py_wide = pd.pivot(turtle_py,\n                          columns = 'sex',\n                          values = 'serum')\n      \n# have a look at the format\nturtle_py_wide.head()\n\nsex  Female   Male\n0       NaN  220.1\n1       NaN  218.6\n2       NaN  229.6\n3       NaN  228.8\n4       NaN  222.0\n\n\n\n# perform the Mann-Whitney U test\n# ignoring the missing values\nstats.mannwhitneyu(turtle_py_wide['Male'],\n                   turtle_py_wide['Female'],\n                   nan_policy = 'omit')\n\nMannwhitneyuResult(statistic=16.0, pvalue=0.5337995337995338)\n\n\n\n\n\nThis gives us exactly the same conclusion that we got from the two-sample t-test i.e. that there isn’t any significant difference between the two groups.\n\nA Mann-Whitney test indicated that there wasn’t a significant difference in the median Serum Cholesterol levels between male and female turtles (W = 26, p = 0.534)"
  },
  {
    "objectID": "cs1_practical_one-sample-t-test.html#libraries-and-functions",
    "href": "cs1_practical_one-sample-t-test.html#libraries-and-functions",
    "title": "One-sample t-test",
    "section": "Libraries and functions",
    "text": "Libraries and functions\n\ntidyverseRPython\n\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nlibrary(tidyverse)\nA collection of R packages designed for data science\n\n\nlibrary(rstatix)\nConverts base R stats functions to a tidyverse-friendly format. Also contains extra functionality that we’ll use.\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nrstatix::t_test()\nPerforms a one-sample t-test, Student’s t-test and Welch’s t-test in later sections.\n\n\nrstatix::shapiro_test()\nPerforms a Shapiro-Wilk test for normality.\n\n\nggplot2::stat_qq()\nPlots a Q-Q plot for comparison with a normal distribution.\n\n\nggplot2::stat_qq_line()\nAdds a comparison line to the Q-Q plot.\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nt.test()\nPerforms a one-sample t-test, Student’s t-test and Welch’s t-test in later sections.\n\n\nqqnorm()\nPlots a Q-Q plot for comparison with a normal distribution.\n\n\nqqline()\nAdds a comparison line to the Q-Q plot.\n\n\nshapiro.test()\nPerforms a Shapiro-Wilk test for normality.\n\n\n\n\n\n\n\n\nLibraries\nDescription\n\n\n\n\nplotnine\nThe Python equivalent of ggplot2.\n\n\npandas\nA Python data analysis and manipulation tool.\n\n\nscipy.stats\nA Python module containing statistical functions.\n\n\n\n\n\n\n\n\n\n\nFunctions\nDescription\n\n\n\n\nscipy.stats.shapiro()\nPerform the Shapiro-Wilk test for normality.\n\n\nscipy.stats.ttest_1samp()\nCalculate the T-test for the mean of ONE group of scores.\n\n\nplotnine.stats.stat_qq()\nPlots a Q-Q plot for comparison with a normal distribution.\n\n\nplotnine.stats.stat_qq_line()\nAdds a comparison line to the Q-Q plot."
  },
  {
    "objectID": "cs1_practical_one-sample-t-test.html#data-and-hypotheses",
    "href": "cs1_practical_one-sample-t-test.html#data-and-hypotheses",
    "title": "One-sample t-test",
    "section": "Data and hypotheses",
    "text": "Data and hypotheses\nFor example, suppose we measure the body lengths of male guppies (in mm) collected from the Guanapo River in Trinidad. We want to test whether the data support the hypothesis that the mean body is actually 20 mm. We form the following null and alternative hypotheses:\n\n\\(H_0\\): The mean body length is equal to 20mm (\\(\\mu =\\) 20).\n\\(H_1\\): The mean body length is not equal to 20mm (\\(\\mu \\neq\\) 20).\n\nWe will use a one-sample, two-tailed t-test to see if we should reject the null hypothesis or not.\n\nWe use a one-sample test because we only have one sample.\nWe use a two-tailed t-test because we want to know if our data suggest that the true (population) mean is different from 20 mm in either direction rather than just to see if it is greater than or less than 20 mm (in which case we would use a one-tailed test).\nWe’re using a t-test because we don’t know any better yet and because I’m telling you to. We’ll look at what the precise assumptions/requirements need to be in a moment.\n\nMake sure you have downloaded the data (see: Datasets) and placed it within your working directory.\n\ntidyverseRPython\n\n\nFirst we load the relevant libraries:\n\n# load tidyverse\nlibrary(tidyverse)\n\n# load rstatix, a tidyverse-friendly stats package\nlibrary(rstatix)\n\nWe then read in the data and create a table containing the data.\n\n# import the data\nfishlengthDF <- read_csv(\"data/CS1-onesample.csv\")\n\nfishlengthDF\n\n# A tibble: 29 × 3\n      id river   length\n   <dbl> <chr>    <dbl>\n 1     1 Guanapo   19.1\n 2     2 Guanapo   23.3\n 3     3 Guanapo   18.2\n 4     4 Guanapo   16.4\n 5     5 Guanapo   19.7\n 6     6 Guanapo   16.6\n 7     7 Guanapo   17.5\n 8     8 Guanapo   19.9\n 9     9 Guanapo   19.1\n10    10 Guanapo   18.8\n# … with 19 more rows\n\n\nThe first line reads the data into R and creates an object called a tibble, which is a type of data frame. This data frame contains 3 columns: a unique id, river encoding the river and length with the measured guppy length.\n\n\nWe then read in the data and create a vector containing the data.\n\n# import the data\nfishlengthDF <- read.csv(\"data/CS1-onesample.csv\")\n\n# create a vector containing the data\nfishlength_r <- fishlengthDF$length\n\nThe first line reads the data into R and creates an object called a data frame. This data frame only contains a single column of numbers called “Guanapo” (the name of the river). In most situations, and for most statistical analyses, having our data stored in a data frame is exactly what we’d want. However, for one sample tests we actually need our data to be stored as a vector. So, the second line extracts the values that are in the Guanapo column of our fishlengthDF data frame and creates a simple vector of numbers that we have called fishlength_r This step is only necessary for one-sample tests and when we look at more complex data sets, we won’t need to do this second step at all.\n\n\nWe then read the data in:\n\n# load the data\nfishlength_py = pd.read_csv('data/CS1-onesample.csv')\n\n# inspect the data\nfishlength_py.head()\n\n   id    river  length\n0   1  Guanapo    19.1\n1   2  Guanapo    23.3\n2   3  Guanapo    18.2\n3   4  Guanapo    16.4\n4   5  Guanapo    19.7"
  },
  {
    "objectID": "cs1_practical_one-sample-t-test.html#summarise-and-visualise",
    "href": "cs1_practical_one-sample-t-test.html#summarise-and-visualise",
    "title": "One-sample t-test",
    "section": "Summarise and visualise",
    "text": "Summarise and visualise\nSummarise the data and visualise it:\n\ntidyverseRPython\n\n\n\nsummary(fishlengthDF)\n\n       id        river               length    \n Min.   : 1   Length:29          Min.   :11.2  \n 1st Qu.: 8   Class :character   1st Qu.:17.5  \n Median :15   Mode  :character   Median :18.8  \n Mean   :15                      Mean   :18.3  \n 3rd Qu.:22                      3rd Qu.:19.7  \n Max.   :29                      Max.   :23.3  \n\nfishlengthDF %>% \n  ggplot(aes(x = river, y = length)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nsummary(fishlength_r)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   11.2    17.5    18.8    18.3    19.7    23.3 \n\nboxplot(fishlength_r, main = \"Male guppies\", ylab = \"Length (mm)\")\n\n\n\n\n\n\nFirst we have a look at a numerical summary of the data:\n\nfishlength_py.describe()\n\n              id     length\ncount  29.000000  29.000000\nmean   15.000000  18.296552\nstd     8.514693   2.584636\nmin     1.000000  11.200000\n25%     8.000000  17.500000\n50%    15.000000  18.800000\n75%    22.000000  19.700000\nmax    29.000000  23.300000\n\n\n\n(\n  ggplot(fishlength_py,\n    aes(x = 'river',\n        y = 'length'))\n  + geom_boxplot()\n)\n\n\n\n\n\n\n\nThe data do not appear to contain any obvious errors, and whilst both the mean and median are less than 20 (18.3 and 18.8 respectively) it is not absolutely certain that the sample mean is sufficiently different from this value to be “statistically significant”, although we may anticipate such a result."
  },
  {
    "objectID": "cs1_practical_one-sample-t-test.html#assumptions",
    "href": "cs1_practical_one-sample-t-test.html#assumptions",
    "title": "One-sample t-test",
    "section": "Assumptions",
    "text": "Assumptions\nWhen it comes to one-sample tests, we have two options:\n\nt-test\nWilcoxon signed-rank test\n\nFor us to use a t-test for this analysis (and for the results to be valid) we have to make two assumptions:\n\nThe parent distribution from which the sample is taken is normally distributed (and as such the sample data are normally distributed themselves).\n\n\n\n\n\n\n\nNote\n\n\n\nIt is worth noting though that the t-test is actually pretty robust in situations where the sample data are not normal. For sufficiently large sample sizes (your guess is as good as mine, but conventionally this means about 30 data points), you can use a t-test without worrying about whether the underlying population is normally distributed or not.\n\n\n\nEach data point in the sample is independent of the others. This is in general not something that can be tested for and instead has to be considered from the sampling procedure. For example, taking repeated measurements from the same individual would generate data that are not independent.\n\nThe second point we know nothing about and so we ignore it here (this is an issue that needs to be considered from the experimental design), whereas the first assumption can be checked. There are three ways of checking for normality:\nIn increasing order of rigour, we have\n\nHistogram\nQuantile-quantile plot\nShapiro-Wilk test\n\n\nHistogram of the data\nPlot a histogram of the data, which gives:\n\ntidyverseRPython\n\n\n\nfishlengthDF %>% \n  ggplot(aes(x = length)) +\n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\nhist(fishlength_r, breaks = 15)\n\n\n\n\n\n\n\n(\n  ggplot(fishlength_py, aes(x = \"length\"))\n  + geom_histogram(bins = 15)\n)\n\n\n\n\n\n\n\nThe distribution appears to be uni-modal and symmetric, and so it isn’t obviously non-normal. However, there are a lot of distributions that have these simple properties but which aren’t normal, so this isn’t exactly rigorous. Thankfully there are other, more rigorous tests.\nNB. By even looking at this distribution to assess the assumption of normality we are already going far beyond what anyone else ever does. Nevertheless, we will continue.\n\n\nQ-Q plot of the data\nQ-Q plot is the short for quantile-quantile plot. This diagnostic plot (as it is sometimes called) is a way of comparing two distributions. How Q-Q plots work won’t be explained here but ask a demonstrator if you really want to know what is going on.\nConstruct a Q-Q Plot of the quantiles of the data against the quantiles of a normal distribution:\n\ntidyverseRPython\n\n\n\nfishlengthDF %>% \n  ggplot(aes(sample = length)) +\n  stat_qq() +\n  stat_qq_line()\n\n\n\n\n\n\n\n# plot the Q-Q plot\nqqnorm(fishlength_r)\n\n# and add a comparison line\nqqline(fishlength_r)\n\n\n\n\n\n\n\n(\n  ggplot(fishlength_py, aes(sample = \"length\"))\n  + stat_qq()\n  + stat_qq_line()\n)\n\n\n\n\n\n\n\nWhat is important to know is that if the data were normally distributed then all of the points should lie on (or close to) the diagonal line in this graph.\nIn this case, the points lie quite close to the line for the most part but the sample quantiles (points) from either end of the sample distribution are either smaller (below the line on the left) or larger (above the line on the right) than expected if they were supposed to be normally distributed. This suggests that the sample distribution is a bit more spread out than would be expected if it came from a normal distribution.\nIt is important to recognise that there isn’t a simple unambiguous answer when interpreting these types of graph, in terms of whether the assumption of normality has been well met or not and instead it often boils down to a matter of experience.\nIt is a very rare situation indeed where the assumptions necessary for a test will be met unequivocally and a certain degree of personal interpretation is always needed. Here you have to ask yourself whether the data are normal “enough” for you to be confident in the validity of the test.\nBelow are four examples of QQ plots for different types of distributions:\n\n\n\n\n\nThese two graphs relate to 200 data points that have been drawn from a normal distribution. Even here you can see that the points do not all lie perfectly on the diagonal line in the QQ plot, and a certain amount of deviation at the top and bottom of the graph can happen just by chance (if I were to draw a different set of point then the graph would look slightly different).\n\n\n\n\n\nThese two graphs relate to 200 data points that have been drawn from a uniform distribution. Uniform distributions are more condensed than normal distributions, and this is reflected in the QQ plot having a very pronounced S-shaped pattern to it (this is colloquially known as snaking).\n\n\n\n\n\nThese two graphs relate to 200 data points that have been drawn from a t distribution. t distributions are more spread out than normal distributions, and this is reflected in the QQ plot again having a very pronounced S-shaped pattern to it, but this time the snaking is a reflection of that observed for the uniform distribution.\n\n\n\n\n\nThese two graphs relate to 200 data points that have been drawn from an exponential distribution. Exponential distributions are not symmetric and are very skewed compared with normal distributions. The significant right-skew in this distribution is reflected in the QQ plot again having points that curve away above the diagonal line at both ends (a left-skew would have the points being below the line at both ends).\nIn all four cases it is worth noting that the deviations are only at the ends of the plot.\n\n\nShapiro-Wilk test\nThis is one of a number of formal statistical test that assess whether a given sample of numbers come from a normal distribution. It calculates the probability of getting the sample data if the underlying distribution is in fact normal. It is very easy to carry out in R.\nPerform a Shapiro-Wilk test on the data:\n\ntidyverseRPython\n\n\n\nfishlengthDF %>% \n  shapiro_test(length)\n\n# A tibble: 1 × 3\n  variable statistic     p\n  <chr>        <dbl> <dbl>\n1 length       0.949 0.176\n\n\n\nvariable indicated the variable that was used to perform the test on\nstatistic gives the calculated W-value (0.9493842)\np gives the calculated p-value (0.1764229)\n\n\n\n\nshapiro.test(fishlength_r)\n\n\n    Shapiro-Wilk normality test\n\ndata:  fishlength_r\nW = 0.94938, p-value = 0.1764\n\n\n\nThe 1st line gives the name of the test and the 2nd line reminds you what the data set was called\nThe 3rd line contains the two key outputs from the test:\nThe calculated w-value is 0.9494 (we don’t need to know this)\nThe p-value is 0.1764\n\n\n\n\nstats.shapiro(fishlength_py.length)\n\nShapiroResult(statistic=0.9493839740753174, pvalue=0.17642046511173248)\n\n\n\n\n\nAs the p-value is bigger than 0.05 (say) then we can say that there is insufficient evidence to reject the null hypothesis that the sample came from a normal distribution.\nIt is important to recognise that the Shapiro-Wilk test is not without limitations. It is rather sensitive to the sample size being considered. In general, for small sample sizes, the test is very relaxed about normality (and nearly all data sets are considered normal), whereas for large sample sizes the test can be overly strict, and it can fail to recognise data sets that are very nearly normal indeed.\n\n\nAssumptions overview\n\n\n\n\n\n\nImportant\n\n\n\nIn terms of assessing the assumptions of a test it is always worth considering several methods, both graphical and analytic, and not just relying on a single method.\n\n\nIn the fishlength example, the graphical Q-Q plot analysis was not especially conclusive as there was some suggestion of snaking in the plots, but the Shapiro-Wilk test gave a non-significant p-value (0.1764). Putting these two together, along with the original histogram and the recognition that there were only 30 data points in the data set I personally would be happy that the assumptions of the t-test were met well enough to trust the result of the t-test, but you may not be…\nIn which case we would consider an alternative test that has less stringent assumptions (but is less powerful): the one-sample Wilcoxon signed-rank test."
  },
  {
    "objectID": "cs1_practical_one-sample-t-test.html#implement-the-test",
    "href": "cs1_practical_one-sample-t-test.html#implement-the-test",
    "title": "One-sample t-test",
    "section": "Implement the test",
    "text": "Implement the test\nPerform a one-sample, two-tailed t-test:\n\ntidyverseRPython\n\n\n\nfishlengthDF %>% \n  t_test(length ~ 1,\n         mu = 20,\n         alternative = \"two.sided\")\n\nThe t_test() function requires three arguments:\n\nthe formula, here we give it length ~ 1 to indicate it is a one-sample test on length\nthe mu is the mean to be tested under the null hypothesis, here it is 20\nthe alternative argument gives the type of alternative hypothesis and must be one of two.sided, greater or less. We have no prior assumptions on whether the alternative fish length would be greater or less than 20, so we choose two.sided.\n\n\n\n\nt.test(fishlength_r,\n       mu = 20,\n       alternative = \"two.sided\")\n\n\n    One Sample t-test\n\ndata:  fishlength_r\nt = -3.5492, df = 28, p-value = 0.001387\nalternative hypothesis: true mean is not equal to 20\n95 percent confidence interval:\n 17.31341 19.27969\nsample estimates:\nmean of x \n 18.29655 \n\n\n\nThe first argument must be a numerical vector of data values.\nThe second argument must be a number and is the mean to be tested under the null hypothesis.\nThe third argument gives the type of alternative hypothesis and must be one of two.sided, greater or less. We have no prior assumptions on whether the alternative fish length would be greater or less than 20, so we choose two.sided.\n\n\n\n\nstats.ttest_1samp(fishlength_py.length,\n                  popmean = 20, \n                  alternative = \"two-sided\")\n\n\nThe first argument must be a numerical series of data values.\nThe second argument must be a number and is the mean to be tested under the null hypothesis.\n\nIn Python you can only two a two-sided 1-sample t-test (i.e. you can only test whether the mean is different from 20 but not whether it is greater than or less than – why they chose to do this is beyond me)."
  },
  {
    "objectID": "cs1_practical_one-sample-t-test.html#interpreting-the-output-and-report-results",
    "href": "cs1_practical_one-sample-t-test.html#interpreting-the-output-and-report-results",
    "title": "One-sample t-test",
    "section": "Interpreting the output and report results",
    "text": "Interpreting the output and report results\nThis is the output that you should now see in the console window:\n\ntidyverseRPython\n\n\n\n\n# A tibble: 1 × 7\n  .y.    group1 group2         n statistic    df       p\n* <chr>  <chr>  <chr>      <int>     <dbl> <dbl>   <dbl>\n1 length 1      null model    29     -3.55    28 0.00139\n\n\n\nthe statistic column gives us the t-statistic of -3.5492 (we’ll need this for reporting)\nthe df column tells us there are 28 degrees of freedom (again we’ll need this for reporting)\nthe p column gives us the p-value of 0.00139\n\n\n\n\n\n\n    One Sample t-test\n\ndata:  fishlength_r\nt = -3.5492, df = 28, p-value = 0.001387\nalternative hypothesis: true mean is not equal to 20\n95 percent confidence interval:\n 17.31341 19.27969\nsample estimates:\nmean of x \n 18.29655 \n\n\n\nThe 1st line gives the name of the test and the 2nd line reminds you what the dataset was called\nThe 3rd line contains the three key outputs from the test:\n\nThe calculated t-value is -3.5492 (we’ll need this for reporting)\nThere are 28 degrees of freedom (again we’ll need this for reporting)\nThe p-value is 0.001387.\n\nThe 4th line simply states the alternative hypothesis\nThe 5th and 6th lines give the 95th confidence interval (we don’t need to know this)\nThe 7th, 8th and 9th lines give the sample mean again (18.29655).\n\n\n\n\n\nTtest_1sampResult(statistic=-3.5491839564647205, pvalue=0.0013868577835348002)\n\n\nThe output is very minimal. The 1st number in brackets is the t-value and the 2nd number is the p-value\n\n\n\nThe p-value is what we’re mostly interested in. It gives the probability of us getting a sample such as ours if the null hypothesis were actually true.\nSo:\n\na high p-value means that there is a high probability of observing a sample such as ours and the null hypothesis is probably true whereas\na low p-value means that there is a low probability of observing a sample such as ours and the null hypothesis is probably not true.\n\nIt is important to realise that the p-value is just an indication and there is no absolute certainty here in this interpretation.\nPeople, however like more definite answers and so we pick an artificial probability threshold (called a significance level) in order to be able to say something more decisive. The standard significance level is 0.05 and since our p-value is smaller than this we choose to say that “it is very unlikely that we would have this particular sample if the null hypothesis were true”. Consequently, we can reject our null hypothesis and state that:\n\nA one-sample t-test indicated that the mean body length of male guppies (\\(\\mu\\) = 18.29mm) differs significantly from 20 mm (t = -3.55, df = 28, p = 0.0014).\n\nThe above sentence is an adequate concluding statement for this test and is what we would write in any paper or report. Note that we have included (in brackets) information on the actual mean value of our group(\\(\\mu\\) = 18.29mm), the test statistic (t = -3.55), the degrees of freedom (df = 28), and the p-value (p = 0.0014). In some journals you are only required to report whether the p-value is less than the critical value (e.g. p < 0.05) but I would always recommend reporting the actual p-value obtained.\nPlease feel free to ask a demonstrator if any aspect of this section is unclear as this does form the core of classical hypothesis testing and the logic here applies to all of the rest of the tests."
  },
  {
    "objectID": "cs1_practical_one-sample-t-test.html#exercise-gastric-juices",
    "href": "cs1_practical_one-sample-t-test.html#exercise-gastric-juices",
    "title": "One-sample t-test",
    "section": "Exercise: gastric juices",
    "text": "Exercise: gastric juices\nThe following data are the dissolving times (in seconds) of a drug in agitated gastric juice:\n42.7, 43.4, 44.6, 45.1, 45.6, 45.9, 46.8, 47.6\nDo these results provide any evidence to suggest that dissolving time for this drug is different from 45 seconds?\n\nCreate a tidy data frame and save it in .csv format\nWrite down the null and alternative hypotheses.\nSummarise and visualise the data and perform an appropriate one-sample t-test.\n\nWhat can you say about the dissolving time? (what sentence would you use to report this)\n\nCheck the assumptions for the test.\n\nWas the test valid?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nHypotheses\n\\(H_0\\) : mean \\(=\\) 45s\n\\(H_1\\) : mean \\(\\neq\\) 45s\n\n\nData, summarise & visualise\nWe can create a data frame in Excel and save it as an .csv file, for example as CS1-gastric_juices.csv. It contains two columns, an id column and a dissolving_time column with the measured values.\n\ntidyverseRPython\n\n\n\n# load the data\ndissolving <- read_csv(\"data/CS1-gastric_juices.csv\")\n\n# have a look at the data\ndissolving\n\n# A tibble: 8 × 2\n     id dissolving_time\n  <dbl>           <dbl>\n1     1            42.7\n2     2            43.4\n3     3            44.6\n4     4            45.1\n5     5            45.6\n6     6            45.9\n7     7            46.8\n8     8            47.6\n\n# summarise the data\nsummary(dissolving)\n\n       id       dissolving_time\n Min.   :1.00   Min.   :42.70  \n 1st Qu.:2.75   1st Qu.:44.30  \n Median :4.50   Median :45.35  \n Mean   :4.50   Mean   :45.21  \n 3rd Qu.:6.25   3rd Qu.:46.12  \n Max.   :8.00   Max.   :47.60  \n\n\nWe can look at the histogram and box plot of the data:\n\n# create a histogram\ndissolving %>% \n  ggplot(aes(x = dissolving_time)) +\n  geom_histogram(bins = 4)\n\n\n\n# create a boxplot\ndissolving %>% \n  ggplot(aes(y = dissolving_time)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n# load the data\ndissolving_r <- read.csv(\"data/CS1-gastric_juices.csv\")\n\n# have a look at the data\ndissolving_r\n\n  id dissolving_time\n1  1            42.7\n2  2            43.4\n3  3            44.6\n4  4            45.1\n5  5            45.6\n6  6            45.9\n7  7            46.8\n8  8            47.6\n\n# summarise the data\nsummary(dissolving_r)\n\n       id       dissolving_time\n Min.   :1.00   Min.   :42.70  \n 1st Qu.:2.75   1st Qu.:44.30  \n Median :4.50   Median :45.35  \n Mean   :4.50   Mean   :45.21  \n 3rd Qu.:6.25   3rd Qu.:46.12  \n Max.   :8.00   Max.   :47.60  \n\n\n\nhist(dissolving_r$dissolving_time)\n\n\n\nboxplot(dissolving_r$dissolving_time)\n\n\n\n\n\n\n\n# load the data\ndissolving_py = pd.read_csv(\"data/CS1-gastric_juices.csv\")\n\n# have a look at the data\ndissolving_py.head()\n\n# summarise the data\n\n   id  dissolving_time\n0   1             42.7\n1   2             43.4\n2   3             44.6\n3   4             45.1\n4   5             45.6\n\ndissolving_py.describe()\n\n            id  dissolving_time\ncount  8.00000         8.000000\nmean   4.50000        45.212500\nstd    2.44949         1.640068\nmin    1.00000        42.700000\n25%    2.75000        44.300000\n50%    4.50000        45.350000\n75%    6.25000        46.125000\nmax    8.00000        47.600000\n\n\nWe can look at the histogram and box plot of the data:\n\n# create a histogram\n(\n  ggplot(dissolving_py,\n    aes(x = \"dissolving_time\"))\n  + geom_histogram(bins = 4)\n)\n\n\n\n\n\n# create a box plot\n(\n  ggplot(dissolving_py,\n    aes(x = 1, y = \"dissolving_time\"))\n  + geom_boxplot()\n)\n\n\n\n\nPython (or plotnine in particular) gets a bit cranky if you try to create a geom_boxplot but do not define the x aesthetic. Hence us putting it as 1. The value is meaningless, however.\n\n\n\nThere are only 8 data points, so the histogram is rather uninformative. Thankfully the box plot is a bit more useful here. We can see:\n\nThere don’t appear to be any major errors in data entry and there aren’t any huge outliers\nThe median value in the box-plot (the thick black line) is pretty close to 45 and so I wouldn’t be surprised if the mean of the data isn’t significantly different from 45. We can confirm that by looking at the mean and median values that we calculated using the summary command from earlier.\nThe data appear to be symmetric, and so whilst we can’t tell if they’re normal they’re a least not massively skewed.\n\n\n\nAssumptions\nNormality:\n\ntidyverseRPython\n\n\n\n# perform Shapiro-Wilk test\ndissolving %>% \n  shapiro_test(dissolving_time)\n\n# A tibble: 1 × 3\n  variable        statistic     p\n  <chr>               <dbl> <dbl>\n1 dissolving_time     0.980 0.964\n\n\n\n# create a Q-Q plot\ndissolving %>% \n  ggplot(aes(sample = dissolving_time)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\")\n\n\n\n\n\n\n\nshapiro.test(dissolving_r$dissolving_time)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dissolving_r$dissolving_time\nW = 0.98023, p-value = 0.9641\n\n\n\nqqnorm(dissolving_r$dissolving_time)\nqqline(dissolving_r$dissolving_time)\n\n\n\n\n\n\n\n# Perform Shapiro-Wilk test to check normality\nstats.shapiro(dissolving_py.dissolving_time)\n\nShapiroResult(statistic=0.9802345037460327, pvalue=0.9640554785728455)\n\n\n\n# Create a Q-Q plot\n(\n  ggplot(dissolving_py,\n    aes(sample = \"dissolving_time\"))\n  + stat_qq()\n  + stat_qq_line()\n)\n\n\n\n\n\n\n\n\nThe Shapiro test has a p-value of 0.964 which (given that it is bigger than 0.05) suggests that the data are normal enough.\nThe Q-Q plot isn’t perfect, with some deviation of the points away from the line but since the points aren’t accelerating away from the line and, since we only have 8 points, we can claim, with some slight reservations, that the assumption of normality appears to be adequately well met.\n\nOverall, we are somewhat confident that the assumption of normality is well-enough met for the t-test to be an appropriate method for analysing the data. Note the ridiculous number of caveats here and the slightly political/slippery language I’m using. This is intentional and reflects the ambiguous nature of assumption checking. This is an important approach to doing statistics that you need to embrace.\nIn reality, if I found myself in this situation I would also try doing a non-parametric test on the data (Wilcoxon signed-rank test) and see whether I get the same conclusion about whether the median dissolving time differs from 45s. Technically, you don’t know about the Wilcoxon test yet as you haven’t done that section of the materials. Anyway, if I get the same conclusion then my confidence in the result of the test goes up considerably; it doesn’t matter how well an assumption has been met, I get the same result. If on the other hand I get a completely different conclusion from carrying out the non-parametric test then all bets are off; I now have very little confidence in my test result as I don’t know which one to believe (in the case that the assumptions of the test are a bit unclear). In this example a Wilcoxon test also gives us a non-significant result and so all is good.\n\n\nImplement test\n\ntidyverseRPython\n\n\n\n# perform one-sample t-test\ndissolving %>% \n  t_test(dissolving_time ~ 1,\n         mu = 45,\n         alternative = \"two.sided\")\n\n# A tibble: 1 × 7\n  .y.             group1 group2         n statistic    df     p\n* <chr>           <chr>  <chr>      <int>     <dbl> <dbl> <dbl>\n1 dissolving_time 1      null model     8     0.366     7 0.725\n\n\n\n\n\nt.test(dissolving_r$dissolving_time,\n       mu = 45 ,\n       alternative = \"two.sided\")\n\n\n    One Sample t-test\n\ndata:  dissolving_r$dissolving_time\nt = 0.36647, df = 7, p-value = 0.7248\nalternative hypothesis: true mean is not equal to 45\n95 percent confidence interval:\n 43.84137 46.58363\nsample estimates:\nmean of x \n  45.2125 \n\n\n\n\n\nstats.ttest_1samp(dissolving_py.dissolving_time,\n                  popmean = 45, \n                  alternative = \"two-sided\")\n\nTtest_1sampResult(statistic=0.36647318560088843, pvalue=0.7248382429835611)\n\n\n\n\n\n\nA one-sample t-test indicated that the mean dissolving time of the drug is not significantly different from 45s (t=0.366 , df=7 , p=0.725)\n\n\n\nAnd that, is that."
  }
]