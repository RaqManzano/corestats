{
  "hash": "d1d5c38855c8e2d5412dab9a0b014cf2",
  "result": {
    "markdown": "---\ntitle: \"Correlations\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n::: callout-tip\n## Learning outcomes\n\n**Questions**\n\n-   What are correlation coefficients?\n-   What kind of correlation coefficients are there and when do I use them?\n\n**Objectives**\n\n-   Be able to calculate correlation coefficients in R or Python\n-   Use visual tools to explore correlations between variables\n-   Know the limitations of correlation coefficients\n:::\n\n## Libraries and functions\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n### Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A collection of R packages designed for data science\nlibrary(tidyverse)\n\n# Converts stats functions to a tidyverse-friendly format\nlibrary(rstatix)\n\n# Creates diagnostic plots using ggplot2\nlibrary(ggResidpanel)\n\n# A package for exploring correlations in R\nlibrary(corrr)\n```\n:::\n\n\n### Functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creates diagnostic plots\nggResidpanel::resid_panel()\n```\n:::\n\n\n## R\n\n## Python\n:::\n:::\n\n## Purpose and aim\n\nCorrelation refers to the relationship of two variables (or data sets) to one another. Two data sets are said to be correlated if they are not independent from one another. Correlations can be useful because they can indicate if a predictive relationship may exist. However just because two data sets are correlated does not mean that they are causally related.\n\n## Data and hypotheses\n\nWe will use the `USArrests` data set for this example. This rather bleak data set contains statistics in arrests per 100,000 residents for assault, murder and robbery in each of the 50 US states in 1973, alongside the proportion of the population who lived in urban areas at that time. `USArrests` is a data frame with 50 observations of five variables: `state`, `murder`, `assault`, `urban_pop` and `robbery`.\n\nWe will be using these data to explore if there are correlations between these variables.\n\nThe data are stored in the file `data/CS3-usarrests.csv`.\n\n## Summarise and visualise\n\nFirst, we load the data:\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\nUSArrests <- read_csv(\"data/CS3-usarrests.csv\")\n\n# have a look at the data\nUSArrests\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 × 5\n   state       murder assault urban_pop robbery\n   <chr>        <dbl>   <dbl>     <dbl>   <dbl>\n 1 Alabama       13.2     236        58    21.2\n 2 Alaska        10       263        48    44.5\n 3 Arizona        8.1     294        80    31  \n 4 Arkansas       8.8     190        50    19.5\n 5 California     9       276        91    40.6\n 6 Colorado       7.9     204        78    38.7\n 7 Connecticut    3.3     110        77    11.1\n 8 Delaware       5.9     238        72    15.8\n 9 Florida       15.4     335        80    31.9\n10 Georgia       17.4     211        60    25.8\n# … with 40 more rows\n```\n:::\n:::\n\n\nWe can create a visual overview of the potential correlations that might exist between the variables. For this, we use the `corrr` package.\n\nMake sure to install the package, if you haven't done so already:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"corrr\")\n```\n:::\n\n\nand then load it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(corrr)\n```\n:::\n\n\nWe can only calculate correlations between numerical variables, so we have to deselect the `state` variable. Next, we calculate the correlations with `correlate()`. We `shave()` off the redundant top results (`murder` vs `assault` is the same as `assault` vs `murder`) and plot the result using `rplot()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create correlation graph\nUSArrests %>% \n    select(-state) %>% \n    correlate() %>% \n    shave() %>% \n    rplot()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nCorrelation method: 'pearson'\nMissing treated using: 'pairwise.complete.obs'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDon't know how to automatically pick scale for object of type noquote. Defaulting to continuous.\n```\n:::\n\n::: {.cell-output-display}\n![](cs3_practical_correlations_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nThe output tells us that the correlation method used is `pearson` (see below) and that only paired observations without missing values are taken into account.\n\nOn the right there is a scale of the strength of the correlation.\n\n## R\n\nFirst, we load the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\nUSArrests_r <- read.csv(\"data/CS3-usarrests.csv\")\n\n# and have a look at the data\nhead(USArrests_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       state murder assault urban_pop robbery\n1    Alabama   13.2     236        58    21.2\n2     Alaska   10.0     263        48    44.5\n3    Arizona    8.1     294        80    31.0\n4   Arkansas    8.8     190        50    19.5\n5 California    9.0     276        91    40.6\n6   Colorado    7.9     204        78    38.7\n```\n:::\n:::\n\n\nWe can only calculate correlations between numerical variables, so we have to deselect the `state` variable.\n\nWe can load the data with an extra argument, `row.names = 1`. This will instruct R to load the data but use first column (`state`) as row names:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the data\nUSArrests_r <- read.csv(\"data/CS3-usarrests.csv\", row.names = 1)\n\n# have a look at the data\nhead(USArrests_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           murder assault urban_pop robbery\nAlabama      13.2     236        58    21.2\nAlaska       10.0     263        48    44.5\nArizona       8.1     294        80    31.0\nArkansas      8.8     190        50    19.5\nCalifornia    9.0     276        91    40.6\nColorado      7.9     204        78    38.7\n```\n:::\n:::\n\n\nWe can visualise the data with the `pairs()` function. This function creates a matrix of scatter plots that we can use to look for correlations. Every combination of variables appears twice (e.g. `murder` vs `assault` is the same as `assault` vs `murder`), so we use the `lower.panel = NULL` argument to only visualise the unique combinations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create matrix of scatter plots\npairs(USArrests_r, lower.panel = NULL)\n```\n\n::: {.cell-output-display}\n![](cs3_practical_correlations_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Python\n:::\n\nFrom the visual inspection we can see that there appears to be a slight positive correlation between all pairs of variables, although this may be very weak in some cases (`murder` and `urban_pop` for example).\n\n::: callout-note\n## Correlation coefficients\n\nThe method we used above is **Pearson's r**. This is a measure of the linear correlation between two variables. It has a value between -1 and +1, where +1 means a perfect positive correlation, -1 means a perfect negative correlation and 0 means no correlation at all.\n\nThere are other correlation coefficients, most notably the **Spearman's rank correlation coefficient**, a non-parametric measure of rank correlation and is generally less sensitive to outliers.\n:::\n\n## Implement and interpret test\n\nA bit earlier we created a graph that visualised the possible correlations between the different variables. Underlying that were the values of Pearson's r. If we want to get the actual values, we can do the following:\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate correlation matrix\nUSArrests %>% \n    select(-state) %>% \n    correlate() %>% \n    shave()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nCorrelation method: 'pearson'\nMissing treated using: 'pairwise.complete.obs'\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 5\n  term       murder assault urban_pop robbery\n  <chr>       <dbl>   <dbl>     <dbl>   <dbl>\n1 murder    NA       NA        NA          NA\n2 assault    0.802   NA        NA          NA\n3 urban_pop  0.0696   0.259    NA          NA\n4 robbery    0.564    0.665     0.411      NA\n```\n:::\n:::\n\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(USArrests_r, method = \"pearson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              murder   assault  urban_pop   robbery\nmurder    1.00000000 0.8018733 0.06957262 0.5635788\nassault   0.80187331 1.0000000 0.25887170 0.6652412\nurban_pop 0.06957262 0.2588717 1.00000000 0.4113412\nrobbery   0.56357883 0.6652412 0.41134124 1.0000000\n```\n:::\n:::\n\n\n*\tThe first argument is a matrix or a data frame\n*\tThe argument `method` tells R which correlation coefficient to use (`pearson` (default), `kendall`, or `spearman`)\n\n## Python\n:::\n\nThe table gives the correlation coefficient between each pair of variables in the data frame. The most correlated variables are murder and assault with an $r$ value of 0.80. This appears to agree well with the set plots that we produced earlier.\n\n## Exercise: Pearson's r for USA state data\nPearson's correlation for USA state data\n\nWe will use the data from the file `data/CS3-statedata.csv` data set for this exercise. This rather more benign data set contains information on more general properties of each US state, such as population (1975), per capita income (1974), illiteracy proportion (1970), life expectancy (1969), murder rate per 100,000 people (there's no getting away from it), percentage of the population who are high-school graduates, average number of days where the minimum temperature is below freezing between 1931 and 1960, and the state area in square miles. The data set contains 50 rows and 8 columns, with column names: `population`, `income`, `illiteracy`, `life_exp`, `murder`, `hs_grad`, `frost` and `area`.\n\nVisually identify 3 different pairs of variables that appear to be\n\n1.\tthe most positively correlated\n2.\tthe most negatively correlated\n3.\tnot correlated at all\n\nCalculate Pearson’s r for all variable pairs and see how well you were able to identify correlation visually.\n\n::: {.callout-tip collapse=\"true\"}\n## Hint\n::: {.panel-tabset group=\"language\"}\n## tidyverse\nLook at the help page of the `stretch()` function from the `corrr` package.\n## R\n## Python\n:::\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Answer\n\nVisually determining the most negative/positively and uncorrelated pairs of variables:\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\n\n::: {.cell}\n\n```{.r .cell-code}\nUSAstate <- read_csv(\"data/CS3-statedata.csv\")\n\n# have a look at the data\nUSAstate\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 × 9\n   state       population income illiteracy life_exp murder hs_grad frost   area\n   <chr>            <dbl>  <dbl>      <dbl>    <dbl>  <dbl>   <dbl> <dbl>  <dbl>\n 1 Alabama           3615   3624        2.1     69.0   15.1    41.3    20  50708\n 2 Alaska             365   6315        1.5     69.3   11.3    66.7   152 566432\n 3 Arizona           2212   4530        1.8     70.6    7.8    58.1    15 113417\n 4 Arkansas          2110   3378        1.9     70.7   10.1    39.9    65  51945\n 5 California       21198   5114        1.1     71.7   10.3    62.6    20 156361\n 6 Colorado          2541   4884        0.7     72.1    6.8    63.9   166 103766\n 7 Connecticut       3100   5348        1.1     72.5    3.1    56     139   4862\n 8 Delaware           579   4809        0.9     70.1    6.2    54.6   103   1982\n 9 Florida           8277   4815        1.3     70.7   10.7    52.6    11  54090\n10 Georgia           4931   4091        2       68.5   13.9    40.6    60  58073\n# … with 40 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# visualise the correlations\nUSAstate %>% \n    select(-state) %>% \n    correlate() %>% \n    shave() %>% \n    rplot()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nCorrelation method: 'pearson'\nMissing treated using: 'pairwise.complete.obs'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDon't know how to automatically pick scale for object of type noquote. Defaulting to continuous.\n```\n:::\n\n::: {.cell-output-display}\n![](cs3_practical_correlations_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n## R\n\n::: {.cell}\n\n```{.r .cell-code}\nUSAstate_r <- read.csv(\"data/CS3-statedata.csv\",\n                     row.names = 1)\n\n# have a look at the data\nhead(USAstate_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           population income illiteracy life_exp murder hs_grad frost   area\nAlabama          3615   3624        2.1    69.05   15.1    41.3    20  50708\nAlaska            365   6315        1.5    69.31   11.3    66.7   152 566432\nArizona          2212   4530        1.8    70.55    7.8    58.1    15 113417\nArkansas         2110   3378        1.9    70.66   10.1    39.9    65  51945\nCalifornia      21198   5114        1.1    71.71   10.3    62.6    20 156361\nColorado         2541   4884        0.7    72.06    6.8    63.9   166 103766\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(USAstate_r, lower.panel = NULL)\n```\n\n::: {.cell-output-display}\n![](cs3_practical_correlations_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n## Python\n:::\n\nIt looks like:\n\n1. `illiteracy` and `murder` are the most positively correlated pair\n2. `life_exp` and `murder` are the most negatively correlated pair\n3. `population` and `area` are the least correlated pair\n\nWe can explore that numerically, by doing the following:\n\n::: {.panel-tabset group=\"language\"}\n## tidyverse\nWe can use the `corrr::stretch()` function. This converts the correlation matrix into a long format. If we use the `remove.dups = TRUE` argument (it is `FALSE` by default) then the duplicate correlations are removed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate the correlation matrix\n# convert into long format, omitting\n# missing values and duplicates\nUSAstate_cor <- USAstate %>% \n    select(-state) %>% \n    correlate() %>% \n    stretch(remove.dups = TRUE) %>% \n    drop_na()\n```\n:::\n\n\nNow we can extract the values we're interested in:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# most positively correlated pair\nUSAstate_cor %>% \n    filter(r == max(r))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  x          y          r\n  <chr>      <chr>  <dbl>\n1 illiteracy murder 0.703\n```\n:::\n\n```{.r .cell-code}\n# most negatively correlated pair\nUSAstate_cor %>% \n    filter(r == min(r))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  x        y           r\n  <chr>    <chr>   <dbl>\n1 life_exp murder -0.781\n```\n:::\n\n```{.r .cell-code}\n# least correlated pair\nUSAstate_cor %>% \n    filter(r == min(abs(r)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  x          y          r\n  <chr>      <chr>  <dbl>\n1 population area  0.0225\n```\n:::\n:::\n\n\nNote that we use the minimum _absolute_ value (with the `abs()` function) to find the least correlated pair.\n\n## R\n## Python\n:::\n\n:::\n",
    "supporting": [
      "cs3_practical_correlations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}